{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f80f5c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, sys\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e0c842c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from data.loader import load_segmentation\n",
    "from utils.session_config import setup_gpus\n",
    "setup_gpus(True, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d646e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.84s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pycocotools.coco import COCO\n",
    "train_ids = np.load(\"annotations/train_ids.npy\")\n",
    "test_ids = np.load(\"annotations/val_ids.npy\")\n",
    "coco = COCO(\"annotations/integrated_annotation.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43ecfb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n",
      "(512, 512)\n"
     ]
    }
   ],
   "source": [
    "train_ds = load_segmentation(train_ids, coco, \"detection\")\n",
    "for patch, mask in train_ds.take(1):\n",
    "    print(patch.shape)\n",
    "    print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "866218e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f56fc76bf60>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mask, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "811b48d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_process(patches, masks):\n",
    "    masks = tf.where(masks == 100, 1, 0)\n",
    "    return patches, masks\n",
    "\n",
    "train_ds = load_segmentation(train_ids, coco, \"detection\", shuffle=True)\n",
    "train_ds = train_ds.cache().batch(16).map(shape_process).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_ds = load_segmentation(test_ids, coco, \"detection\")\n",
    "test_ds = test_ds.batch(16).map(shape_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d73517a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 512, 512, 3)\n",
      "(32, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "for patches, masks in train_ds.take(1):\n",
    "    print(patches.shape)\n",
    "    print(masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb4940e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f6032b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06afdf66",
   "metadata": {},
   "source": [
    "# 모델 빌드 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d21063e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"models/segmentation.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0cec65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BCE = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "@tf.function\n",
    "def train_step(patches, masks, model, optimizer, train_loss, train_acc):\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds = model(patches, training=True)\n",
    "        loss = BCE(masks,preds)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_acc(labels, preds)\n",
    "@tf.function\n",
    "def test_step(patches, masks, model, test_loss, test_acc):\n",
    "    preds = model(patches, training=False)\n",
    "    loss = BCE(masks,preds)\n",
    "    test_loss(loss)\n",
    "    test_acc(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948bbaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_acc = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_acc = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "template = \"Epoch {} : detection train loss {:5f}, accuracy {:.3f}, val loss {:5f}, val accuracy {:.3f}\"\n",
    "optimizer= tf.keras.optimizers.Adam(learning_rate=1E-3)\n",
    "EPOCH = 20\n",
    "\n",
    "log_dir = \"logs/segmentation\"\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "for epoch in range(1, EPOCH+1): \n",
    "    train_loss.reset_states()\n",
    "    train_acc.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_acc.reset_states()\n",
    "\n",
    "    for i, (patches, masks) in enumerate(train_ds):\n",
    "        train_step(patches, masks, model, optimizer, \\\n",
    "                             train_loss, train_acc)\n",
    "        print(\"Epoch : {} train_step : {}\".format(epoch, i))\n",
    "        \n",
    "    for i, (patches, labels) in enumerate(test_ds):\n",
    "        test_step(patches, masks, model, test_loss, test_acc)\n",
    "    print(template.format(epoch,\n",
    "                      train_loss.result().numpy(),\n",
    "                      train_acc.result().numpy(),\n",
    "                     test_loss.result().numpy(),\n",
    "                     test_acc.result().numpy()))\n",
    "\n",
    "    with summary_writer.as_default():\n",
    "        tf.summary.scalar('train_loss', train_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('train_acc', train_acc.result().numpy(), step=epoch)\n",
    "        tf.summary.scalar('test_loss', test_loss.result().numpy(), step=epoch)\n",
    "        tf.summary.scalar('test_acc', test_acc.result().numpy(), step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0555acf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"checkpoints/segmentation/model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e102c62",
   "metadata": {},
   "source": [
    "# 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b58e738",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_modelval_ds = val_ds.map(lambda x: tf.py_function(data_process, [x], [tf.float32, tf.int32])).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.map(lambda x: tf.py_function(data_process, [x], [tf.float32, tf.int32])).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.map(lambda x: tf.py_function(data_process, [x], [tf.float32, tf.int32])).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.map(lambda x: tf.py_function(data_process, [x], [tf.float32, tf.int32])).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.map(lambda x: tf.py_function(data_process, [x], [tf.float32, tf.int32])).prefetch(buffer_size=AUTOTUNE)\n",
    "(\"checkpoints/detection/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bd8f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.data.Dataset.from_tensor_slices(val_ids).cache().batch(1)\n",
    "val_ds = val_ds.map(lambda x: tf.py_function(data_process, [x], [tf.float32, tf.int32])).prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dc358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, label in val_ds.take(1):\n",
    "    print(img.shape)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd04f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "for r in range(5):\n",
    "    for c in range(4):\n",
    "        ax = fig.add_subplot(5,4,r*4 + c + 1)\n",
    "        if r*4+c+1>19:\n",
    "            break\n",
    "        ax.imshow((img[r*4+c]+1)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25ec957",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46ad067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
