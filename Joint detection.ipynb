{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f80f5c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import json, os, sys\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from data.loader import load_detection\n",
    "from utils.session_config import setup_gpus\n",
    "setup_gpus(True, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d646e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.72s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pycocotools.coco import COCO\n",
    "train_ids = np.load(\"annotations/train_ids.npy\")\n",
    "test_ids = np.load(\"annotations/val_ids.npy\")\n",
    "coco = COCO(\"annotations/integrated_annotation.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac8d053",
   "metadata": {},
   "source": [
    "# 학습데이터 생성 (파일저장) 이미 파일 생성했을 경우 실행 X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43ecfb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds = load_detection(train_ids, coco, \"detection\")\n",
    "# for patches, labels in train_ds.take(1):\n",
    "#     print(patches.shape)\n",
    "#     print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "862881e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch_id = 0\n",
    "# for patches, labels in train_ds:\n",
    "#     for patch, label in zip(patches, labels):\n",
    "#         patch_id+=1\n",
    "#         patch_array = patch.numpy()\n",
    "#         label = label.numpy()\n",
    "#         cv2.imwrite(\"detection/patches/{:06d}-{}.png\".format(patch_id, label), patch_array[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a20128e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_ds = load_detection(test_ids, coco, \"detection\")\n",
    "# for patches, labels in test_ds.take(1):\n",
    "#     print(patches.shape)\n",
    "#     print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f454b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch_id = 0\n",
    "# for patches, labels in test_ds:\n",
    "#     for patch, label in zip(patches, labels):\n",
    "#         patch_id+=1\n",
    "#         patch_array = patch.numpy()\n",
    "#         label = label.numpy()\n",
    "#         cv2.imwrite(\"detection/patches/test/{:06d}-{}.png\".format(patch_id, label), patch_array[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db6f9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b600aa6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b728e039",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "720bae68",
   "metadata": {},
   "source": [
    "# data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a19570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = tf.strings.split\n",
    "\n",
    "def decode_img(img):\n",
    "  # convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.image.decode_jpeg(img, channels=3)\n",
    "  return img\n",
    "\n",
    "def get_label(file_path):\n",
    "  # convert the path to a list of path components\n",
    "  #parts = tf.strings.split(file_path, [\"-\",\".png\"])\n",
    "  # The second to last is the class-directory\n",
    "  label = int(split(split(file_path, \"-\")[1], \".png\")[0])\n",
    "  return label\n",
    "\n",
    "def data_process(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98e2f1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.data.Dataset.list_files(\"detection/patches/train/*\")\n",
    "train_ds = train_ds.shuffle(buffer_size=10000, reshuffle_each_iteration=False)\n",
    "train_ds = train_ds.shuffle(1000).map(data_process)\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(images.shape)\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a001b97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "test_ds = tf.data.Dataset.list_files(\"detection/patches/test/*\")\n",
    "test_ds = test_ds.shuffle(1000).map(data_process)\n",
    "for images, labels in test_ds.take(1):\n",
    "    print(images.shape)\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a799f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_ds = test_ds.batch(32).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb9b6118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 224, 224, 3)\n",
      "tf.Tensor([0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0], shape=(32,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_ds.take(1):\n",
    "    print(images.shape)\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06afdf66",
   "metadata": {},
   "source": [
    "# 모델 빌드 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d21063e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"models/detection.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0cec65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CCE = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "def class_weights_on_CCE(labels, preds):\n",
    "    loss = CCE(labels, preds)\n",
    "    class_weight = tf.where(labels > 0, 10.0, 1.0)\n",
    "    return tf.reduce_mean(loss*class_weight)\n",
    "    \n",
    "@tf.function\n",
    "def train_step(images, labels, model, optimizer, train_loss, train_acc):\n",
    "    with tf.GradientTape() as tape:\n",
    "        images = tf.keras.applications.mobilenet_v2.preprocess_input(images)\n",
    "        preds = model(images, training=True)\n",
    "        loss = class_weights_on_CCE(labels,preds)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_acc(labels, preds)\n",
    "    return loss\n",
    "@tf.function\n",
    "def test_step(images, labels, model, test_loss, test_acc):\n",
    "    images = tf.keras.applications.mobilenet_v2.preprocess_input(images)\n",
    "    preds = model(images, training=False)\n",
    "    loss = class_weights_on_CCE(labels,preds)\n",
    "    test_loss(loss)\n",
    "    test_acc(labels, preds)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948bbaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 train_step : 0 loss 1.2557700872421265\n",
      "Epoch : 1 train_step : 1 loss 1.768409013748169\n",
      "Epoch : 1 train_step : 2 loss 0.8349640369415283\n",
      "Epoch : 1 train_step : 3 loss 0.9307219386100769\n",
      "Epoch : 1 train_step : 4 loss 0.6780959963798523\n",
      "Epoch : 1 train_step : 5 loss 0.6969061493873596\n",
      "Epoch : 1 train_step : 6 loss 0.6439228057861328\n",
      "Epoch : 1 train_step : 7 loss 0.3394489288330078\n",
      "Epoch : 1 train_step : 8 loss 0.6408264636993408\n",
      "Epoch : 1 train_step : 9 loss 0.3299618065357208\n",
      "Epoch : 1 train_step : 10 loss 0.29225626587867737\n",
      "Epoch : 1 train_step : 11 loss 0.29940173029899597\n",
      "Epoch : 1 train_step : 12 loss 0.16543874144554138\n",
      "Epoch : 1 train_step : 13 loss 0.33421191573143005\n",
      "Epoch : 1 train_step : 14 loss 0.28710877895355225\n",
      "Epoch : 1 train_step : 15 loss 0.23311859369277954\n",
      "Epoch : 1 train_step : 16 loss 0.38644254207611084\n",
      "Epoch : 1 train_step : 17 loss 0.060135938227176666\n",
      "Epoch : 1 train_step : 18 loss 0.9124174118041992\n",
      "Epoch : 1 train_step : 19 loss 0.07163576781749725\n",
      "Epoch : 1 train_step : 20 loss 0.04530753195285797\n",
      "Epoch : 1 train_step : 21 loss 0.12993669509887695\n",
      "Epoch : 1 train_step : 22 loss 0.8222857117652893\n",
      "Epoch : 1 train_step : 23 loss 0.48827582597732544\n",
      "Epoch : 1 train_step : 24 loss 0.14931726455688477\n",
      "Epoch : 1 train_step : 25 loss 0.09899695217609406\n",
      "Epoch : 1 train_step : 26 loss 0.08635936677455902\n",
      "Epoch : 1 train_step : 27 loss 0.12575210630893707\n",
      "Epoch : 1 train_step : 28 loss 0.1195918545126915\n",
      "Epoch : 1 train_step : 29 loss 0.11671262979507446\n",
      "Epoch : 1 train_step : 30 loss 0.15968835353851318\n",
      "Epoch : 1 train_step : 31 loss 0.10444357991218567\n",
      "Epoch : 1 train_step : 32 loss 0.040310412645339966\n",
      "Epoch : 1 train_step : 33 loss 0.10680877417325974\n",
      "Epoch : 1 train_step : 34 loss 0.12985467910766602\n",
      "Epoch : 1 train_step : 35 loss 0.06866398453712463\n",
      "Epoch : 1 train_step : 36 loss 0.17188860476016998\n",
      "Epoch : 1 train_step : 37 loss 0.1478108912706375\n",
      "Epoch : 1 train_step : 38 loss 0.19510290026664734\n",
      "Epoch : 1 train_step : 39 loss 0.11456194519996643\n",
      "Epoch : 1 train_step : 40 loss 0.21806740760803223\n",
      "Epoch : 1 train_step : 41 loss 0.20652130246162415\n",
      "Epoch : 1 train_step : 42 loss 0.1540127694606781\n",
      "Epoch : 1 train_step : 43 loss 1.4838957786560059\n",
      "Epoch : 1 train_step : 44 loss 0.03655919060111046\n",
      "Epoch : 1 train_step : 45 loss 0.03584364801645279\n",
      "Epoch : 1 train_step : 46 loss 0.05243887007236481\n",
      "Epoch : 1 train_step : 47 loss 0.7320414781570435\n",
      "Epoch : 1 train_step : 48 loss 0.1014319658279419\n",
      "Epoch : 1 train_step : 49 loss 0.14939475059509277\n",
      "Epoch : 1 train_step : 50 loss 0.4663577973842621\n",
      "Epoch : 1 train_step : 51 loss 0.25026729702949524\n",
      "Epoch : 1 train_step : 52 loss 0.4431570768356323\n",
      "Epoch : 1 train_step : 53 loss 0.24684865772724152\n",
      "Epoch : 1 train_step : 54 loss 0.019446508958935738\n",
      "Epoch : 1 train_step : 55 loss 0.25685304403305054\n",
      "Epoch : 1 train_step : 56 loss 0.13014958798885345\n",
      "Epoch : 1 train_step : 57 loss 0.1554301381111145\n",
      "Epoch : 1 train_step : 58 loss 0.11056941747665405\n",
      "Epoch : 1 train_step : 59 loss 0.04271317273378372\n",
      "Epoch : 1 train_step : 60 loss 0.08578100055456161\n",
      "Epoch : 1 train_step : 61 loss 0.02445283532142639\n",
      "Epoch : 1 train_step : 62 loss 0.04667845368385315\n",
      "Epoch : 1 train_step : 63 loss 0.4204298257827759\n",
      "Epoch : 1 train_step : 64 loss 0.13764561712741852\n",
      "Epoch : 1 train_step : 65 loss 0.07853399217128754\n",
      "Epoch : 1 train_step : 66 loss 0.07877978682518005\n",
      "Epoch : 1 train_step : 67 loss 0.037096984684467316\n",
      "Epoch : 1 train_step : 68 loss 0.19096121191978455\n",
      "Epoch : 1 train_step : 69 loss 0.0350777842104435\n",
      "Epoch : 1 train_step : 70 loss 0.13238929212093353\n",
      "Epoch : 1 train_step : 71 loss 1.7842681407928467\n",
      "Epoch : 1 train_step : 72 loss 0.03654349222779274\n",
      "Epoch : 1 train_step : 73 loss 0.04664042592048645\n",
      "Epoch : 1 train_step : 74 loss 0.04752381518483162\n",
      "Epoch : 1 train_step : 75 loss 1.5498015880584717\n",
      "Epoch : 1 train_step : 76 loss 0.06022816151380539\n",
      "Epoch : 1 train_step : 77 loss 0.03777864947915077\n",
      "Epoch : 1 train_step : 78 loss 0.07797376811504364\n",
      "Epoch : 1 train_step : 79 loss 0.04427175223827362\n",
      "Epoch : 1 train_step : 80 loss 0.19782787561416626\n",
      "Epoch : 1 train_step : 81 loss 0.15967963635921478\n",
      "Epoch : 1 train_step : 82 loss 0.15096279978752136\n",
      "Epoch : 1 train_step : 83 loss 0.0349695086479187\n",
      "Epoch : 1 train_step : 84 loss 0.3347957730293274\n",
      "Epoch : 1 train_step : 85 loss 0.05021221935749054\n",
      "Epoch : 1 train_step : 86 loss 0.18370786309242249\n",
      "Epoch : 1 train_step : 87 loss 0.05608994513750076\n",
      "Epoch : 1 train_step : 88 loss 0.5740201473236084\n",
      "Epoch : 1 train_step : 89 loss 0.02670956216752529\n",
      "Epoch : 1 train_step : 90 loss 0.25547659397125244\n",
      "Epoch : 1 train_step : 91 loss 0.061019167304039\n",
      "Epoch : 1 train_step : 92 loss 0.06796757131814957\n",
      "Epoch : 1 train_step : 93 loss 0.08826156705617905\n",
      "Epoch : 1 train_step : 94 loss 0.3161119222640991\n",
      "Epoch : 1 train_step : 95 loss 0.25281351804733276\n",
      "Epoch : 1 train_step : 96 loss 0.10476946085691452\n",
      "Epoch : 1 train_step : 97 loss 0.3223905861377716\n",
      "Epoch : 1 train_step : 98 loss 0.08684052526950836\n",
      "Epoch : 1 train_step : 99 loss 0.16292154788970947\n",
      "Epoch : 1 train_step : 100 loss 0.07618360221385956\n",
      "Epoch : 1 train_step : 101 loss 0.06506650894880295\n",
      "Epoch : 1 train_step : 102 loss 0.21143314242362976\n",
      "Epoch : 1 train_step : 103 loss 0.15043967962265015\n",
      "Epoch : 1 train_step : 104 loss 0.12144883722066879\n",
      "Epoch : 1 train_step : 105 loss 0.13216377794742584\n",
      "Epoch : 1 train_step : 106 loss 0.27023130655288696\n",
      "Epoch : 1 train_step : 107 loss 0.05408678576350212\n",
      "Epoch : 1 train_step : 108 loss 1.2601224184036255\n",
      "Epoch : 1 train_step : 109 loss 0.03922712057828903\n",
      "Epoch : 1 train_step : 110 loss 0.7203985452651978\n",
      "Epoch : 1 train_step : 111 loss 0.037152405828237534\n",
      "Epoch : 1 train_step : 112 loss 0.08743515610694885\n",
      "Epoch : 1 train_step : 113 loss 0.12377730756998062\n",
      "Epoch : 1 train_step : 114 loss 0.13767103850841522\n",
      "Epoch : 1 train_step : 115 loss 0.1222732812166214\n",
      "Epoch : 1 train_step : 116 loss 0.07747359573841095\n",
      "Epoch : 1 train_step : 117 loss 0.06801740825176239\n",
      "Epoch : 1 train_step : 118 loss 0.2642144560813904\n",
      "Epoch : 1 train_step : 119 loss 0.20393556356430054\n",
      "Epoch : 1 train_step : 120 loss 0.11845932900905609\n",
      "Epoch : 1 train_step : 121 loss 0.7069718837738037\n",
      "Epoch : 1 train_step : 122 loss 0.22991244494915009\n",
      "Epoch : 1 train_step : 123 loss 0.129400372505188\n",
      "Epoch : 1 train_step : 124 loss 0.23239095509052277\n",
      "Epoch : 1 train_step : 125 loss 0.21634453535079956\n",
      "Epoch : 1 train_step : 126 loss 0.02535468153655529\n",
      "Epoch : 1 train_step : 127 loss 0.10993435978889465\n",
      "Epoch : 1 train_step : 128 loss 0.27420368790626526\n",
      "Epoch : 1 train_step : 129 loss 0.026853268966078758\n",
      "Epoch : 1 train_step : 130 loss 0.11211025714874268\n",
      "Epoch : 1 train_step : 131 loss 0.09844217449426651\n",
      "Epoch : 1 train_step : 132 loss 0.16036561131477356\n",
      "Epoch : 1 train_step : 133 loss 0.12348859012126923\n",
      "Epoch : 1 train_step : 134 loss 0.1066620945930481\n",
      "Epoch : 1 train_step : 135 loss 0.09158024191856384\n",
      "Epoch : 1 train_step : 136 loss 0.42379629611968994\n",
      "Epoch : 1 train_step : 137 loss 0.08771310746669769\n",
      "Epoch : 1 train_step : 138 loss 0.13751772046089172\n",
      "Epoch : 1 train_step : 139 loss 1.20121431350708\n",
      "Epoch : 1 train_step : 140 loss 0.020894600078463554\n",
      "Epoch : 1 train_step : 141 loss 0.10767148435115814\n",
      "Epoch : 1 train_step : 142 loss 0.3579486012458801\n",
      "Epoch : 1 train_step : 143 loss 0.05441684275865555\n",
      "Epoch : 1 train_step : 144 loss 0.06573553383350372\n",
      "Epoch : 1 train_step : 145 loss 0.22692927718162537\n",
      "Epoch : 1 train_step : 146 loss 0.3846622705459595\n",
      "Epoch : 1 train_step : 147 loss 0.27851295471191406\n",
      "Epoch : 1 train_step : 148 loss 0.07788415998220444\n",
      "Epoch : 1 train_step : 149 loss 0.1892515867948532\n",
      "Epoch : 1 train_step : 150 loss 0.28731808066368103\n",
      "Epoch : 1 train_step : 151 loss 0.12609004974365234\n",
      "Epoch : 1 train_step : 152 loss 0.19498248398303986\n",
      "Epoch : 1 train_step : 153 loss 0.16013139486312866\n",
      "Epoch : 1 train_step : 154 loss 0.2657194435596466\n",
      "Epoch : 1 train_step : 155 loss 0.08920605480670929\n",
      "Epoch : 1 train_step : 156 loss 0.07267451286315918\n",
      "Epoch : 1 train_step : 157 loss 0.11149607598781586\n",
      "Epoch : 1 train_step : 158 loss 0.07917636632919312\n",
      "Epoch : 1 train_step : 159 loss 0.14259952306747437\n",
      "Epoch : 1 train_step : 160 loss 0.1736421138048172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 train_step : 161 loss 0.06992606818675995\n",
      "Epoch : 1 train_step : 162 loss 0.10603301972150803\n",
      "Epoch : 1 train_step : 163 loss 0.07758985459804535\n",
      "Epoch : 1 train_step : 164 loss 0.15356135368347168\n",
      "Epoch : 1 train_step : 165 loss 0.19485339522361755\n",
      "Epoch : 1 train_step : 166 loss 0.4642188251018524\n",
      "Epoch : 1 train_step : 167 loss 0.1547860950231552\n",
      "Epoch : 1 train_step : 168 loss 0.022875532507896423\n",
      "Epoch : 1 train_step : 169 loss 0.12438929826021194\n",
      "Epoch : 1 train_step : 170 loss 0.07753923535346985\n",
      "Epoch : 1 train_step : 171 loss 0.1715589314699173\n",
      "Epoch : 1 train_step : 172 loss 0.08041395246982574\n",
      "Epoch : 1 train_step : 173 loss 0.4429000914096832\n",
      "Epoch : 1 train_step : 174 loss 0.04848792776465416\n",
      "Epoch : 1 train_step : 175 loss 0.15417706966400146\n",
      "Epoch : 1 train_step : 176 loss 0.2023467719554901\n",
      "Epoch : 1 train_step : 177 loss 0.14526036381721497\n",
      "Epoch : 1 train_step : 178 loss 0.03582043945789337\n",
      "Epoch : 1 train_step : 179 loss 0.07978653162717819\n",
      "Epoch : 1 train_step : 180 loss 0.1589595377445221\n",
      "Epoch : 1 train_step : 181 loss 0.3047402501106262\n",
      "Epoch : 1 train_step : 182 loss 0.018490001559257507\n",
      "Epoch : 1 train_step : 183 loss 0.2076086699962616\n",
      "Epoch : 1 train_step : 184 loss 0.19619032740592957\n",
      "Epoch : 1 train_step : 185 loss 0.15182290971279144\n",
      "Epoch : 1 train_step : 186 loss 0.1511186808347702\n",
      "Epoch : 1 train_step : 187 loss 0.0653277337551117\n",
      "Epoch : 1 train_step : 188 loss 0.06885737180709839\n",
      "Epoch : 1 train_step : 189 loss 1.7290228605270386\n",
      "Epoch : 1 train_step : 190 loss 0.18596747517585754\n",
      "Epoch : 1 train_step : 191 loss 0.05361735820770264\n",
      "Epoch : 1 train_step : 192 loss 0.108074851334095\n",
      "Epoch : 1 train_step : 193 loss 0.05879007652401924\n",
      "Epoch : 1 train_step : 194 loss 0.07931578159332275\n",
      "Epoch : 1 train_step : 195 loss 0.5442765355110168\n",
      "Epoch : 1 train_step : 196 loss 0.05425873398780823\n",
      "Epoch : 1 train_step : 197 loss 0.01648646779358387\n",
      "Epoch : 1 train_step : 198 loss 0.07692545652389526\n",
      "Epoch : 1 train_step : 199 loss 0.11093094944953918\n",
      "Epoch : 1 train_step : 200 loss 0.06003820523619652\n",
      "Epoch : 1 train_step : 201 loss 0.029684944078326225\n",
      "Epoch : 1 train_step : 202 loss 0.06381525099277496\n",
      "Epoch : 1 train_step : 203 loss 0.04819035530090332\n",
      "Epoch : 1 train_step : 204 loss 0.033454589545726776\n",
      "Epoch : 1 train_step : 205 loss 0.17395555973052979\n",
      "Epoch : 1 train_step : 206 loss 0.09726589173078537\n",
      "Epoch : 1 train_step : 207 loss 0.0669003278017044\n",
      "Epoch : 1 train_step : 208 loss 0.4063551723957062\n",
      "Epoch : 1 train_step : 209 loss 0.1454450488090515\n",
      "Epoch : 1 train_step : 210 loss 0.02059144899249077\n",
      "Epoch : 1 train_step : 211 loss 0.20257844030857086\n",
      "Epoch : 1 train_step : 212 loss 0.13657104969024658\n",
      "Epoch : 1 train_step : 213 loss 0.026049233973026276\n",
      "Epoch : 1 train_step : 214 loss 0.310156911611557\n",
      "Epoch : 1 train_step : 215 loss 0.03961917757987976\n",
      "Epoch : 1 train_step : 216 loss 0.019561685621738434\n",
      "Epoch : 1 train_step : 217 loss 0.16772335767745972\n",
      "Epoch : 1 train_step : 218 loss 0.14669141173362732\n",
      "Epoch : 1 train_step : 219 loss 0.0887811928987503\n",
      "Epoch : 1 train_step : 220 loss 0.1707080453634262\n",
      "Epoch : 1 train_step : 221 loss 0.18589062988758087\n",
      "Epoch : 1 train_step : 222 loss 0.07961560785770416\n",
      "Epoch : 1 train_step : 223 loss 0.11539982259273529\n",
      "Epoch : 1 train_step : 224 loss 0.0662306398153305\n",
      "Epoch : 1 train_step : 225 loss 0.021609872579574585\n",
      "Epoch : 1 train_step : 226 loss 0.04429567977786064\n",
      "Epoch : 1 train_step : 227 loss 0.017384080216288567\n",
      "Epoch : 1 train_step : 228 loss 0.12534703314304352\n",
      "Epoch : 1 train_step : 229 loss 0.10972415655851364\n",
      "Epoch : 1 train_step : 230 loss 0.0285366028547287\n",
      "Epoch : 1 train_step : 231 loss 0.059335723519325256\n",
      "Epoch : 1 train_step : 232 loss 0.14382371306419373\n",
      "Epoch : 1 train_step : 233 loss 0.019334081560373306\n",
      "Epoch : 1 train_step : 234 loss 0.021351264789700508\n",
      "Epoch : 1 train_step : 235 loss 0.020245857536792755\n",
      "Epoch : 1 train_step : 236 loss 0.1337081640958786\n",
      "Epoch : 1 train_step : 237 loss 0.01442418061196804\n",
      "Epoch : 1 train_step : 238 loss 0.012461320497095585\n",
      "Epoch : 1 train_step : 239 loss 0.225001722574234\n",
      "Epoch : 1 train_step : 240 loss 0.029424216598272324\n",
      "Epoch : 1 train_step : 241 loss 0.9180337190628052\n",
      "Epoch : 1 train_step : 242 loss 0.014957038685679436\n",
      "Epoch : 1 train_step : 243 loss 0.012089232914149761\n",
      "Epoch : 1 train_step : 244 loss 0.00796529557555914\n",
      "Epoch : 1 train_step : 245 loss 0.03882703185081482\n",
      "Epoch : 1 train_step : 246 loss 0.16783757507801056\n",
      "Epoch : 1 train_step : 247 loss 0.7351414561271667\n",
      "Epoch : 1 train_step : 248 loss 0.015005910769104958\n",
      "Epoch : 1 train_step : 249 loss 0.3432757258415222\n",
      "Epoch : 1 train_step : 250 loss 0.09096972644329071\n",
      "Epoch : 1 train_step : 251 loss 0.028703566640615463\n",
      "Epoch : 1 train_step : 252 loss 0.6662049889564514\n",
      "Epoch : 1 train_step : 253 loss 0.015804201364517212\n",
      "Epoch : 1 train_step : 254 loss 0.024836555123329163\n",
      "Epoch : 1 train_step : 255 loss 0.013280795887112617\n",
      "Epoch : 1 train_step : 256 loss 0.09137120097875595\n",
      "Epoch : 1 train_step : 257 loss 0.02497873082756996\n",
      "Epoch : 1 train_step : 258 loss 0.08768386393785477\n",
      "Epoch : 1 train_step : 259 loss 0.10148509591817856\n",
      "Epoch : 1 train_step : 260 loss 0.418972909450531\n",
      "Epoch : 1 train_step : 261 loss 0.03253914788365364\n",
      "Epoch : 1 train_step : 262 loss 0.38441580533981323\n",
      "Epoch : 1 train_step : 263 loss 0.053112275898456573\n",
      "Epoch : 1 train_step : 264 loss 0.05052035674452782\n",
      "Epoch : 1 train_step : 265 loss 0.030570801347494125\n",
      "Epoch : 1 train_step : 266 loss 0.07510870695114136\n",
      "Epoch : 1 train_step : 267 loss 0.1952371895313263\n",
      "Epoch : 1 train_step : 268 loss 0.04895561933517456\n",
      "Epoch : 1 train_step : 269 loss 0.025581441819667816\n",
      "Epoch : 1 train_step : 270 loss 0.026330752298235893\n",
      "Epoch : 1 train_step : 271 loss 0.06114565208554268\n",
      "Epoch : 1 train_step : 272 loss 0.02954087220132351\n",
      "Epoch : 1 train_step : 273 loss 0.034535545855760574\n",
      "Epoch : 1 train_step : 274 loss 0.04035266488790512\n",
      "Epoch : 1 train_step : 275 loss 0.04514075815677643\n",
      "Epoch : 1 train_step : 276 loss 0.781363844871521\n",
      "Epoch : 1 train_step : 277 loss 0.020789969712495804\n",
      "Epoch : 1 train_step : 278 loss 0.004363861866295338\n",
      "Epoch : 1 train_step : 279 loss 0.055982135236263275\n",
      "Epoch : 1 train_step : 280 loss 0.059859827160835266\n",
      "Epoch : 1 train_step : 281 loss 0.14174288511276245\n",
      "Epoch : 1 train_step : 282 loss 0.05775236338376999\n",
      "Epoch : 1 train_step : 283 loss 0.12291228026151657\n",
      "Epoch : 1 train_step : 284 loss 0.01723150722682476\n",
      "Epoch : 1 train_step : 285 loss 0.654122531414032\n",
      "Epoch : 1 train_step : 286 loss 0.013475997373461723\n",
      "Epoch : 1 train_step : 287 loss 0.04960450157523155\n",
      "Epoch : 1 train_step : 288 loss 0.013346662744879723\n",
      "Epoch : 1 train_step : 289 loss 0.026350410655140877\n",
      "Epoch : 1 train_step : 290 loss 0.2565069794654846\n",
      "Epoch : 1 train_step : 291 loss 0.0404495894908905\n",
      "Epoch : 1 train_step : 292 loss 0.029154419898986816\n",
      "Epoch : 1 train_step : 293 loss 0.34341496229171753\n",
      "Epoch : 1 train_step : 294 loss 0.04455231502652168\n",
      "Epoch : 1 train_step : 295 loss 0.020912840962409973\n",
      "Epoch : 1 train_step : 296 loss 0.07031397521495819\n",
      "Epoch : 1 train_step : 297 loss 0.054338619112968445\n",
      "Epoch : 1 train_step : 298 loss 0.06349574774503708\n",
      "Epoch : 1 train_step : 299 loss 0.1048436313867569\n",
      "Epoch : 1 train_step : 300 loss 0.20279842615127563\n",
      "Epoch : 1 train_step : 301 loss 0.33475059270858765\n",
      "Epoch : 1 train_step : 302 loss 0.10969869792461395\n",
      "Epoch : 1 train_step : 303 loss 0.12118849903345108\n",
      "Epoch : 1 train_step : 304 loss 0.06493283808231354\n",
      "Epoch : 1 train_step : 305 loss 0.10130526125431061\n",
      "Epoch : 1 train_step : 306 loss 0.12339112162590027\n",
      "Epoch : 1 train_step : 307 loss 0.05720037966966629\n",
      "Epoch : 1 train_step : 308 loss 0.06132779270410538\n",
      "Epoch : 1 train_step : 309 loss 0.06870201230049133\n",
      "Epoch : 1 train_step : 310 loss 0.03891662135720253\n",
      "Epoch : 1 train_step : 311 loss 0.338911235332489\n",
      "Epoch : 1 train_step : 312 loss 0.23987893760204315\n",
      "Epoch : 1 train_step : 313 loss 0.15399271249771118\n",
      "Epoch : 1 train_step : 314 loss 1.280840516090393\n",
      "Epoch : 1 train_step : 315 loss 0.585450291633606\n",
      "Epoch : 1 train_step : 316 loss 0.0529271624982357\n",
      "Epoch : 1 train_step : 317 loss 0.014174357987940311\n",
      "Epoch : 1 train_step : 318 loss 0.14214572310447693\n",
      "Epoch : 1 train_step : 319 loss 0.11193092167377472\n",
      "Epoch : 1 train_step : 320 loss 0.0693676546216011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 train_step : 321 loss 0.353592187166214\n",
      "Epoch : 1 train_step : 322 loss 0.13538143038749695\n",
      "Epoch : 1 train_step : 323 loss 0.06367988884449005\n",
      "Epoch : 1 train_step : 324 loss 0.06835617870092392\n",
      "Epoch : 1 train_step : 325 loss 0.01644078642129898\n",
      "Epoch : 1 train_step : 326 loss 0.06339332461357117\n",
      "Epoch : 1 train_step : 327 loss 0.33568114042282104\n",
      "Epoch : 1 train_step : 328 loss 0.05097506195306778\n",
      "Epoch : 1 train_step : 329 loss 0.6701114177703857\n",
      "Epoch : 1 train_step : 330 loss 0.06259266287088394\n",
      "Epoch : 1 train_step : 331 loss 0.06241527944803238\n",
      "Epoch : 1 train_step : 332 loss 0.22165414690971375\n",
      "Epoch : 1 train_step : 333 loss 0.14288926124572754\n",
      "Epoch : 1 train_step : 334 loss 0.06962452828884125\n",
      "Epoch : 1 train_step : 335 loss 0.22340527176856995\n",
      "Epoch : 1 train_step : 336 loss 0.3150361180305481\n",
      "Epoch : 1 train_step : 337 loss 0.37813279032707214\n",
      "Epoch : 1 train_step : 338 loss 0.08620001375675201\n",
      "Epoch : 1 train_step : 339 loss 0.1246015802025795\n",
      "Epoch : 1 train_step : 340 loss 0.2797028720378876\n",
      "Epoch : 1 train_step : 341 loss 0.07244554907083511\n",
      "Epoch : 1 train_step : 342 loss 0.23842617869377136\n",
      "Epoch : 1 train_step : 343 loss 0.1191597729921341\n",
      "Epoch : 1 train_step : 344 loss 0.180188849568367\n",
      "Epoch : 1 train_step : 345 loss 0.18110182881355286\n",
      "Epoch : 1 train_step : 346 loss 0.08925025165081024\n",
      "Epoch : 1 train_step : 347 loss 0.1467168927192688\n",
      "Epoch : 1 train_step : 348 loss 0.16668099164962769\n",
      "Epoch : 1 train_step : 349 loss 0.029384201392531395\n",
      "Epoch : 1 train_step : 350 loss 0.2266036570072174\n",
      "Epoch : 1 train_step : 351 loss 0.09207259863615036\n",
      "Epoch : 1 train_step : 352 loss 0.07755418121814728\n",
      "Epoch : 1 train_step : 353 loss 0.09702585637569427\n",
      "Epoch : 1 train_step : 354 loss 0.12065919488668442\n",
      "Epoch : 1 train_step : 355 loss 0.01989530213177204\n",
      "Epoch : 1 train_step : 356 loss 2.6084628105163574\n",
      "Epoch : 1 train_step : 357 loss 0.4297280013561249\n",
      "Epoch : 1 train_step : 358 loss 0.7463839054107666\n",
      "Epoch : 1 train_step : 359 loss 0.1277889460325241\n",
      "Epoch : 1 train_step : 360 loss 0.03964872658252716\n",
      "Epoch : 1 train_step : 361 loss 0.2580697536468506\n",
      "Epoch : 1 train_step : 362 loss 0.1912555694580078\n",
      "Epoch : 1 train_step : 363 loss 0.14530041813850403\n",
      "Epoch : 1 train_step : 364 loss 1.3513128757476807\n",
      "Epoch : 1 train_step : 365 loss 0.08132122457027435\n",
      "Epoch : 1 train_step : 366 loss 0.35067495703697205\n",
      "Epoch : 1 train_step : 367 loss 0.20707789063453674\n",
      "Epoch : 1 train_step : 368 loss 0.1993478685617447\n",
      "Epoch : 1 train_step : 369 loss 0.5788241028785706\n",
      "Epoch : 1 train_step : 370 loss 0.11114705353975296\n",
      "Epoch : 1 train_step : 371 loss 0.06823186576366425\n",
      "Epoch : 1 train_step : 372 loss 0.2951274514198303\n",
      "Epoch : 1 train_step : 373 loss 0.16401465237140656\n",
      "Epoch : 1 train_step : 374 loss 0.37881362438201904\n",
      "Epoch : 1 train_step : 375 loss 0.14981520175933838\n",
      "Epoch : 1 train_step : 376 loss 0.42208561301231384\n",
      "Epoch : 1 train_step : 377 loss 0.47541236877441406\n",
      "Epoch : 1 train_step : 378 loss 0.0714123547077179\n",
      "Epoch : 1 train_step : 379 loss 0.13055357336997986\n",
      "Epoch : 1 train_step : 380 loss 0.2507054805755615\n",
      "Epoch : 1 train_step : 381 loss 0.2828136086463928\n",
      "Epoch : 1 train_step : 382 loss 0.08536671847105026\n",
      "Epoch : 1 train_step : 383 loss 0.32853448390960693\n",
      "Epoch : 1 train_step : 384 loss 0.2121601700782776\n",
      "Epoch : 1 train_step : 385 loss 0.06395842134952545\n",
      "Epoch : 1 train_step : 386 loss 0.07367492467164993\n",
      "Epoch : 1 train_step : 387 loss 0.12011465430259705\n",
      "Epoch : 1 train_step : 388 loss 0.16052639484405518\n",
      "Epoch : 1 train_step : 389 loss 0.12623000144958496\n",
      "Epoch : 1 train_step : 390 loss 0.043599605560302734\n",
      "Epoch : 1 train_step : 391 loss 0.18283773958683014\n",
      "Epoch : 1 train_step : 392 loss 0.10290226340293884\n",
      "Epoch : 1 train_step : 393 loss 0.07461895048618317\n",
      "Epoch : 1 train_step : 394 loss 0.07024481147527695\n",
      "Epoch : 1 train_step : 395 loss 0.051849476993083954\n",
      "Epoch : 1 train_step : 396 loss 0.05713889002799988\n",
      "Epoch : 1 train_step : 397 loss 0.18716105818748474\n",
      "Epoch : 1 train_step : 398 loss 0.07369957864284515\n",
      "Epoch : 1 train_step : 399 loss 0.23205499351024628\n",
      "Epoch : 1 train_step : 400 loss 0.430181086063385\n",
      "Epoch : 1 train_step : 401 loss 0.06319712847471237\n",
      "Epoch : 1 train_step : 402 loss 0.09266412258148193\n",
      "Epoch : 1 train_step : 403 loss 0.05662879720330238\n",
      "Epoch : 1 train_step : 404 loss 0.08743059635162354\n",
      "Epoch : 1 train_step : 405 loss 0.14095938205718994\n",
      "Epoch : 1 train_step : 406 loss 1.0584443807601929\n",
      "Epoch : 1 train_step : 407 loss 0.2565114200115204\n",
      "Epoch : 1 train_step : 408 loss 0.2128673493862152\n",
      "Epoch : 1 train_step : 409 loss 3.5348823070526123\n",
      "Epoch : 1 train_step : 410 loss 0.01820448413491249\n",
      "Epoch : 1 train_step : 411 loss 0.029855502769351006\n",
      "Epoch : 1 train_step : 412 loss 0.11946071684360504\n",
      "Epoch : 1 train_step : 413 loss 0.05681653320789337\n",
      "Epoch : 1 train_step : 414 loss 0.1547221541404724\n",
      "Epoch : 1 train_step : 415 loss 0.1445963978767395\n",
      "Epoch : 1 train_step : 416 loss 0.0682874247431755\n",
      "Epoch : 1 train_step : 417 loss 0.10716766119003296\n",
      "Epoch : 1 train_step : 418 loss 0.09204626083374023\n",
      "Epoch : 1 train_step : 419 loss 0.19399160146713257\n",
      "Epoch : 1 train_step : 420 loss 0.08478350192308426\n",
      "Epoch : 1 train_step : 421 loss 0.07794173061847687\n",
      "Epoch : 1 train_step : 422 loss 0.13105875253677368\n",
      "Epoch : 1 train_step : 423 loss 0.14499349892139435\n",
      "Epoch : 1 train_step : 424 loss 0.08721049129962921\n",
      "Epoch : 1 train_step : 425 loss 0.10423469543457031\n",
      "Epoch : 1 train_step : 426 loss 0.20066624879837036\n",
      "Epoch : 1 train_step : 427 loss 0.13496281206607819\n",
      "Epoch : 1 train_step : 428 loss 0.10824286937713623\n",
      "Epoch : 1 train_step : 429 loss 0.10414224863052368\n",
      "Epoch : 1 train_step : 430 loss 0.10541150718927383\n",
      "Epoch : 1 train_step : 431 loss 0.08198846876621246\n",
      "Epoch : 1 train_step : 432 loss 0.042723022401332855\n",
      "Epoch : 1 train_step : 433 loss 0.07084985077381134\n",
      "Epoch : 1 train_step : 434 loss 0.1291639357805252\n",
      "Epoch : 1 train_step : 435 loss 0.06298545002937317\n",
      "Epoch : 1 train_step : 436 loss 0.05416248366236687\n",
      "Epoch : 1 train_step : 437 loss 1.4611175060272217\n",
      "Epoch : 1 train_step : 438 loss 0.08700890094041824\n",
      "Epoch : 1 train_step : 439 loss 0.280105322599411\n",
      "Epoch : 1 train_step : 440 loss 0.06723833084106445\n",
      "Epoch : 1 train_step : 441 loss 0.08533954620361328\n",
      "Epoch : 1 train_step : 442 loss 0.19923776388168335\n",
      "Epoch : 1 train_step : 443 loss 0.053820494562387466\n",
      "Epoch : 1 train_step : 444 loss 0.20720598101615906\n",
      "Epoch : 1 train_step : 445 loss 0.24451470375061035\n",
      "Epoch : 1 train_step : 446 loss 0.11229655891656876\n",
      "Epoch : 1 train_step : 447 loss 0.08604148030281067\n",
      "Epoch : 1 train_step : 448 loss 0.06013122946023941\n",
      "Epoch : 1 train_step : 449 loss 0.10125815868377686\n",
      "Epoch : 1 train_step : 450 loss 0.3720170855522156\n",
      "Epoch : 1 train_step : 451 loss 0.11431585997343063\n",
      "Epoch : 1 train_step : 452 loss 0.1942068636417389\n",
      "Epoch : 1 train_step : 453 loss 0.05237611010670662\n",
      "Epoch : 1 train_step : 454 loss 0.677430272102356\n",
      "Epoch : 1 train_step : 455 loss 0.30622804164886475\n",
      "Epoch : 1 train_step : 456 loss 0.08177820593118668\n",
      "Epoch : 1 train_step : 457 loss 0.4117860198020935\n",
      "Epoch : 1 train_step : 458 loss 0.03482186049222946\n",
      "Epoch : 1 train_step : 459 loss 0.05580456182360649\n",
      "Epoch : 1 train_step : 460 loss 0.05970529094338417\n",
      "Epoch : 1 train_step : 461 loss 0.18290051817893982\n",
      "Epoch : 1 train_step : 462 loss 0.022285887971520424\n",
      "Epoch : 1 train_step : 463 loss 0.11014509201049805\n",
      "Epoch : 1 train_step : 464 loss 0.03728187829256058\n",
      "Epoch : 1 train_step : 465 loss 0.09485769271850586\n",
      "Epoch : 1 train_step : 466 loss 0.06211799383163452\n",
      "Epoch : 1 train_step : 467 loss 0.1614934504032135\n",
      "Epoch : 1 train_step : 468 loss 0.19984859228134155\n",
      "Epoch : 1 train_step : 469 loss 0.2866268754005432\n",
      "Epoch : 1 train_step : 470 loss 0.023306624963879585\n",
      "Epoch : 1 train_step : 471 loss 0.02017287351191044\n",
      "Epoch : 1 train_step : 472 loss 0.040746383368968964\n",
      "Epoch : 1 train_step : 473 loss 0.01170118898153305\n",
      "Epoch : 1 train_step : 474 loss 0.05007306486368179\n",
      "Epoch : 1 train_step : 475 loss 0.15038448572158813\n",
      "Epoch : 1 train_step : 476 loss 0.29978713393211365\n",
      "Epoch : 1 train_step : 477 loss 0.06794150173664093\n",
      "Epoch : 1 train_step : 478 loss 0.5207870602607727\n",
      "Epoch : 1 train_step : 479 loss 0.17113012075424194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 train_step : 480 loss 0.03809880092740059\n",
      "Epoch : 1 train_step : 481 loss 0.08321724832057953\n",
      "Epoch : 1 train_step : 482 loss 0.06432035565376282\n",
      "Epoch : 1 train_step : 483 loss 0.07559433579444885\n",
      "Epoch : 1 train_step : 484 loss 0.2708359956741333\n",
      "Epoch : 1 train_step : 485 loss 0.011483363807201385\n",
      "Epoch : 1 train_step : 486 loss 0.08508798480033875\n",
      "Epoch : 1 train_step : 487 loss 0.08089686930179596\n",
      "Epoch : 1 train_step : 488 loss 0.07930120080709457\n",
      "Epoch : 1 train_step : 489 loss 0.02019275352358818\n",
      "Epoch : 1 train_step : 490 loss 0.13631753623485565\n",
      "Epoch : 1 train_step : 491 loss 0.1274237036705017\n",
      "Epoch : 1 train_step : 492 loss 0.026390381157398224\n",
      "Epoch : 1 train_step : 493 loss 0.09457455575466156\n",
      "Epoch : 1 train_step : 494 loss 0.03710094839334488\n",
      "Epoch : 1 train_step : 495 loss 0.06604766100645065\n",
      "Epoch : 1 train_step : 496 loss 0.23349860310554504\n",
      "Epoch : 1 train_step : 497 loss 0.04394947737455368\n",
      "Epoch : 1 train_step : 498 loss 0.05376672372221947\n",
      "Epoch : 1 train_step : 499 loss 0.07148084789514542\n",
      "Epoch : 1 train_step : 500 loss 0.11823858320713043\n",
      "Epoch : 1 train_step : 501 loss 0.049280546605587006\n",
      "Epoch : 1 train_step : 502 loss 0.041280679404735565\n",
      "Epoch : 1 train_step : 503 loss 0.0036969175562262535\n",
      "Epoch : 1 train_step : 504 loss 0.012579412199556828\n",
      "Epoch : 1 train_step : 505 loss 0.06463272869586945\n",
      "Epoch : 1 train_step : 506 loss 0.007747129071503878\n",
      "Epoch : 1 train_step : 507 loss 0.060761481523513794\n",
      "Epoch : 1 train_step : 508 loss 0.03681720793247223\n",
      "Epoch : 1 train_step : 509 loss 0.01910346746444702\n",
      "Epoch : 1 train_step : 510 loss 0.03592561185359955\n",
      "Epoch : 1 train_step : 511 loss 0.011934053152799606\n",
      "Epoch : 1 train_step : 512 loss 0.28651803731918335\n",
      "Epoch : 1 train_step : 513 loss 0.006071354728192091\n",
      "Epoch : 1 train_step : 514 loss 0.009266483597457409\n",
      "Epoch : 1 train_step : 515 loss 0.01572343148291111\n",
      "Epoch : 1 train_step : 516 loss 0.04032829776406288\n",
      "Epoch : 1 train_step : 517 loss 0.11726105958223343\n",
      "Epoch : 1 train_step : 518 loss 0.011081157252192497\n",
      "Epoch : 1 train_step : 519 loss 0.0049004643224179745\n",
      "Epoch : 1 train_step : 520 loss 0.024516716599464417\n",
      "Epoch : 1 train_step : 521 loss 0.02419121563434601\n",
      "Epoch : 1 train_step : 522 loss 0.23547929525375366\n",
      "Epoch : 1 train_step : 523 loss 0.039803989231586456\n",
      "Epoch : 1 train_step : 524 loss 0.01662970706820488\n",
      "Epoch : 1 train_step : 525 loss 0.05015506595373154\n",
      "Epoch : 1 train_step : 526 loss 0.17559361457824707\n",
      "Epoch : 1 train_step : 527 loss 0.018631331622600555\n",
      "Epoch : 1 train_step : 528 loss 0.057512618601322174\n",
      "Epoch : 1 train_step : 529 loss 0.38642239570617676\n",
      "Epoch : 1 train_step : 530 loss 0.33033955097198486\n",
      "Epoch : 1 train_step : 531 loss 0.005546563304960728\n",
      "Epoch : 1 train_step : 532 loss 0.0885976105928421\n",
      "Epoch : 1 train_step : 533 loss 0.12651124596595764\n",
      "Epoch : 1 train_step : 534 loss 0.03367520123720169\n",
      "Epoch : 1 train_step : 535 loss 0.005130409728735685\n",
      "Epoch : 1 train_step : 536 loss 0.019316470250487328\n",
      "Epoch : 1 train_step : 537 loss 0.0039461953565478325\n",
      "Epoch : 1 train_step : 538 loss 0.03565536066889763\n",
      "Epoch : 1 train_step : 539 loss 0.07344146072864532\n",
      "Epoch : 1 train_step : 540 loss 0.6955835819244385\n",
      "Epoch : 1 train_step : 541 loss 0.09250277280807495\n",
      "Epoch : 1 train_step : 542 loss 0.018155135214328766\n",
      "Epoch : 1 train_step : 543 loss 0.00217081094160676\n",
      "Epoch : 1 train_step : 544 loss 0.01854008249938488\n",
      "Epoch : 1 train_step : 545 loss 0.21300452947616577\n",
      "Epoch : 1 train_step : 546 loss 0.02126496657729149\n",
      "Epoch : 1 train_step : 547 loss 0.01277866866439581\n",
      "Epoch : 1 train_step : 548 loss 0.005431185942143202\n",
      "Epoch : 1 train_step : 549 loss 0.07712887972593307\n",
      "Epoch : 1 train_step : 550 loss 0.07623879611492157\n",
      "Epoch : 1 train_step : 551 loss 0.031811200082302094\n",
      "Epoch : 1 train_step : 552 loss 0.002189106773585081\n",
      "Epoch : 1 train_step : 553 loss 0.174490824341774\n",
      "Epoch : 1 train_step : 554 loss 0.05884794518351555\n",
      "Epoch : 1 train_step : 555 loss 0.13676853477954865\n",
      "Epoch : 1 train_step : 556 loss 0.13404646515846252\n",
      "Epoch : 1 train_step : 557 loss 0.11511646211147308\n",
      "Epoch : 1 train_step : 558 loss 0.054574839770793915\n",
      "Epoch : 1 train_step : 559 loss 0.002575812628492713\n",
      "Epoch : 1 train_step : 560 loss 0.40635907649993896\n",
      "Epoch : 1 train_step : 561 loss 0.05398568511009216\n",
      "Epoch : 1 train_step : 562 loss 0.0971442386507988\n",
      "Epoch : 1 train_step : 563 loss 0.09211884438991547\n",
      "Epoch : 1 train_step : 564 loss 0.1335027813911438\n",
      "Epoch : 1 train_step : 565 loss 0.019462788477540016\n",
      "Epoch : 1 train_step : 566 loss 0.042099785059690475\n",
      "Epoch : 1 train_step : 567 loss 0.03478701040148735\n",
      "Epoch : 1 train_step : 568 loss 0.07985370606184006\n",
      "Epoch : 1 train_step : 569 loss 0.04012628644704819\n",
      "Epoch : 1 train_step : 570 loss 0.009646609425544739\n",
      "Epoch : 1 train_step : 571 loss 1.8739997148513794\n",
      "Epoch : 1 train_step : 572 loss 0.013048666529357433\n",
      "Epoch : 1 train_step : 573 loss 0.2550571858882904\n",
      "Epoch : 1 train_step : 574 loss 0.05393324792385101\n",
      "Epoch : 1 train_step : 575 loss 0.03637951612472534\n",
      "Epoch : 1 train_step : 576 loss 0.1291864514350891\n",
      "Epoch : 1 train_step : 577 loss 0.06243167072534561\n",
      "Epoch : 1 train_step : 578 loss 0.06927353888750076\n",
      "Epoch : 1 train_step : 579 loss 0.13405241072177887\n",
      "Epoch : 1 train_step : 580 loss 0.05219608545303345\n",
      "Epoch : 1 train_step : 581 loss 0.04396102949976921\n",
      "Epoch : 1 train_step : 582 loss 0.17788180708885193\n",
      "Epoch : 1 train_step : 583 loss 0.2631928324699402\n",
      "Epoch : 1 train_step : 584 loss 0.1435767263174057\n",
      "Epoch : 1 train_step : 585 loss 0.17749331891536713\n",
      "Epoch : 1 train_step : 586 loss 0.10283775627613068\n",
      "Epoch : 1 train_step : 587 loss 0.039302997291088104\n",
      "Epoch : 1 train_step : 588 loss 0.01656644232571125\n",
      "Epoch : 1 train_step : 589 loss 0.05508152395486832\n",
      "Epoch : 1 train_step : 590 loss 0.03806384280323982\n",
      "Epoch : 1 train_step : 591 loss 0.07525505125522614\n",
      "Epoch : 1 train_step : 592 loss 0.054297927767038345\n",
      "Epoch : 1 train_step : 593 loss 0.09718533605337143\n",
      "Epoch : 1 train_step : 594 loss 0.02082809805870056\n",
      "Epoch : 1 train_step : 595 loss 0.02248532697558403\n",
      "Epoch : 1 train_step : 596 loss 0.042373765259981155\n",
      "Epoch : 1 train_step : 597 loss 0.06869959831237793\n",
      "Epoch : 1 train_step : 598 loss 1.4099147319793701\n",
      "Epoch : 1 train_step : 599 loss 0.09978868812322617\n",
      "Epoch : 1 train_step : 600 loss 0.04392062500119209\n",
      "Epoch : 1 train_step : 601 loss 0.05257971212267876\n",
      "Epoch : 1 train_step : 602 loss 0.37090593576431274\n",
      "Epoch : 1 train_step : 603 loss 0.08614975214004517\n",
      "Epoch : 1 train_step : 604 loss 0.011815469712018967\n",
      "Epoch : 1 train_step : 605 loss 0.1523338258266449\n",
      "Epoch : 1 train_step : 606 loss 0.19447819888591766\n",
      "Epoch : 1 train_step : 607 loss 0.10204233229160309\n",
      "Epoch : 1 train_step : 608 loss 0.07679872214794159\n",
      "Epoch : 1 train_step : 609 loss 0.176682248711586\n",
      "Epoch : 1 train_step : 610 loss 0.04958547651767731\n",
      "Epoch : 1 train_step : 611 loss 0.1794951856136322\n",
      "Epoch : 1 train_step : 612 loss 0.29533109068870544\n",
      "Epoch : 1 train_step : 613 loss 0.4551125168800354\n",
      "Epoch : 1 train_step : 614 loss 1.1022312641143799\n",
      "Epoch : 1 train_step : 615 loss 0.1822812259197235\n",
      "Epoch : 1 train_step : 616 loss 0.11975257843732834\n",
      "Epoch : 1 train_step : 617 loss 0.11659638583660126\n",
      "Epoch : 1 train_step : 618 loss 0.0672299712896347\n",
      "Epoch : 1 train_step : 619 loss 0.16384652256965637\n",
      "Epoch : 1 train_step : 620 loss 0.4438211917877197\n",
      "Epoch : 1 train_step : 621 loss 0.10245981067419052\n",
      "Epoch : 1 train_step : 622 loss 0.0697246640920639\n",
      "Epoch : 1 train_step : 623 loss 0.09740603715181351\n",
      "Epoch : 1 train_step : 624 loss 0.1595311462879181\n",
      "Epoch : 1 train_step : 625 loss 0.06333579868078232\n",
      "Epoch : 1 train_step : 626 loss 0.11422622948884964\n",
      "Epoch : 1 train_step : 627 loss 0.1548565924167633\n",
      "Epoch : 1 train_step : 628 loss 0.0560176819562912\n",
      "Epoch : 1 train_step : 629 loss 0.0678197517991066\n",
      "Epoch : 1 train_step : 630 loss 0.09798780828714371\n",
      "Epoch : 1 train_step : 631 loss 0.15139570832252502\n",
      "Epoch : 1 train_step : 632 loss 0.0335521325469017\n",
      "Epoch : 1 train_step : 633 loss 0.334736704826355\n",
      "Epoch : 1 train_step : 634 loss 0.052520666271448135\n",
      "Epoch : 1 train_step : 635 loss 0.027567259967327118\n",
      "Epoch : 1 train_step : 636 loss 0.020855067297816277\n",
      "Epoch : 1 train_step : 637 loss 0.036266788840293884\n",
      "Epoch : 1 train_step : 638 loss 0.020006956532597542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 train_step : 639 loss 0.028124932199716568\n",
      "Epoch : 1 train_step : 640 loss 0.14579804241657257\n",
      "Epoch : 1 train_step : 641 loss 0.023551490157842636\n",
      "Epoch : 1 train_step : 642 loss 0.09026038646697998\n",
      "Epoch : 1 train_step : 643 loss 0.01626165583729744\n",
      "Epoch : 1 train_step : 644 loss 0.17691220343112946\n",
      "Epoch : 1 train_step : 645 loss 0.22671189904212952\n",
      "Epoch : 1 train_step : 646 loss 0.08400142937898636\n",
      "Epoch : 1 train_step : 647 loss 0.06991039216518402\n",
      "Epoch : 1 train_step : 648 loss 0.027809133753180504\n",
      "Epoch : 1 train_step : 649 loss 0.05203789845108986\n",
      "Epoch : 1 train_step : 650 loss 0.03233852609992027\n",
      "Epoch : 1 train_step : 651 loss 0.04955676570534706\n",
      "Epoch : 1 train_step : 652 loss 0.11007604002952576\n",
      "Epoch : 1 train_step : 653 loss 0.031069085001945496\n",
      "Epoch : 1 train_step : 654 loss 0.0017131385393440723\n",
      "Epoch : 1 train_step : 655 loss 0.014912966638803482\n",
      "Epoch : 1 train_step : 656 loss 0.30865707993507385\n",
      "Epoch : 1 train_step : 657 loss 0.013705599121749401\n",
      "Epoch : 1 train_step : 658 loss 0.053541529923677444\n",
      "Epoch : 1 train_step : 659 loss 0.0403103232383728\n",
      "Epoch : 1 train_step : 660 loss 0.22763818502426147\n",
      "Epoch : 1 train_step : 661 loss 0.01815973035991192\n",
      "Epoch : 1 train_step : 662 loss 0.06839191168546677\n",
      "Epoch : 1 train_step : 663 loss 0.045812804251909256\n",
      "Epoch : 1 train_step : 664 loss 0.02111700549721718\n",
      "Epoch : 1 train_step : 665 loss 0.04106452316045761\n",
      "Epoch : 1 train_step : 666 loss 0.10024461150169373\n",
      "Epoch : 1 train_step : 667 loss 0.044495731592178345\n",
      "Epoch : 1 train_step : 668 loss 0.10773992538452148\n",
      "Epoch : 1 train_step : 669 loss 0.043886151164770126\n",
      "Epoch : 1 train_step : 670 loss 0.130601167678833\n",
      "Epoch : 1 train_step : 671 loss 0.038385529071092606\n",
      "Epoch : 1 train_step : 672 loss 0.01059060636907816\n",
      "Epoch : 1 train_step : 673 loss 0.0123850516974926\n",
      "Epoch : 1 train_step : 674 loss 0.025146054103970528\n",
      "Epoch : 1 train_step : 675 loss 0.8444817662239075\n",
      "Epoch : 1 train_step : 676 loss 0.01328795962035656\n",
      "Epoch : 1 train_step : 677 loss 0.11281901597976685\n",
      "Epoch : 1 train_step : 678 loss 0.013239694759249687\n",
      "Epoch : 1 train_step : 679 loss 0.08311553299427032\n",
      "Epoch : 1 train_step : 680 loss 0.058938950300216675\n",
      "Epoch : 1 train_step : 681 loss 0.018139667809009552\n",
      "Epoch : 1 train_step : 682 loss 0.04605858772993088\n",
      "Epoch : 1 train_step : 683 loss 0.02440151572227478\n",
      "Epoch : 1 train_step : 684 loss 0.02374371699988842\n",
      "Epoch : 1 train_step : 685 loss 0.0849647969007492\n",
      "Epoch : 1 train_step : 686 loss 0.09362015873193741\n",
      "Epoch : 1 train_step : 687 loss 0.03243960812687874\n",
      "Epoch : 1 train_step : 688 loss 0.07122427225112915\n",
      "Epoch : 1 train_step : 689 loss 0.09710708260536194\n",
      "Epoch : 1 train_step : 690 loss 0.099041648209095\n",
      "Epoch : 1 train_step : 691 loss 0.13523021340370178\n",
      "Epoch : 1 train_step : 692 loss 0.17089462280273438\n",
      "Epoch : 1 train_step : 693 loss 0.07160023599863052\n",
      "Epoch : 1 train_step : 694 loss 0.051459990441799164\n",
      "Epoch : 1 train_step : 695 loss 0.164809912443161\n",
      "Epoch : 1 train_step : 696 loss 0.004417570773512125\n",
      "Epoch : 1 train_step : 697 loss 0.03769989311695099\n",
      "Epoch : 1 train_step : 698 loss 0.03775706887245178\n",
      "Epoch : 1 train_step : 699 loss 0.09444861114025116\n",
      "Epoch : 1 train_step : 700 loss 0.1224600076675415\n",
      "Epoch : 1 train_step : 701 loss 0.030435416847467422\n",
      "Epoch : 1 train_step : 702 loss 0.04409806430339813\n",
      "Epoch : 1 train_step : 703 loss 0.016838504001498222\n",
      "Epoch : 1 train_step : 704 loss 0.216232568025589\n",
      "Epoch : 1 train_step : 705 loss 0.09795334935188293\n",
      "Epoch : 1 train_step : 706 loss 0.02151104249060154\n",
      "Epoch : 1 train_step : 707 loss 0.06130242720246315\n",
      "Epoch : 1 train_step : 708 loss 0.15966251492500305\n",
      "Epoch : 1 train_step : 709 loss 0.3593760132789612\n",
      "Epoch : 1 train_step : 710 loss 0.027428267523646355\n",
      "Epoch : 1 train_step : 711 loss 0.036479219794273376\n",
      "Epoch : 1 train_step : 712 loss 0.09344810247421265\n",
      "Epoch : 1 train_step : 713 loss 0.07789890468120575\n",
      "Epoch : 1 train_step : 714 loss 0.04779219999909401\n",
      "Epoch : 1 train_step : 715 loss 0.011957529932260513\n",
      "Epoch : 1 train_step : 716 loss 0.03744729980826378\n",
      "Epoch : 1 train_step : 717 loss 0.03199304640293121\n",
      "Epoch : 1 train_step : 718 loss 0.02972310036420822\n",
      "Epoch : 1 train_step : 719 loss 0.0388018824160099\n",
      "Epoch : 1 train_step : 720 loss 0.03294197842478752\n",
      "Epoch : 1 train_step : 721 loss 0.036765094846487045\n",
      "Epoch : 1 train_step : 722 loss 1.314529538154602\n",
      "Epoch : 1 train_step : 723 loss 0.011479824781417847\n",
      "Epoch : 1 train_step : 724 loss 0.054436586797237396\n",
      "Epoch : 1 train_step : 725 loss 0.004668630193918943\n",
      "Epoch : 1 train_step : 726 loss 0.003641424234956503\n",
      "Epoch : 1 train_step : 727 loss 0.5730509161949158\n",
      "Epoch : 1 train_step : 728 loss 0.04163157194852829\n",
      "Epoch : 1 train_step : 729 loss 0.04093477129936218\n",
      "Epoch : 1 train_step : 730 loss 0.029787037521600723\n",
      "Epoch : 1 train_step : 731 loss 0.027436748147010803\n",
      "Epoch : 1 train_step : 732 loss 0.014253596775233746\n",
      "Epoch : 1 train_step : 733 loss 0.20242661237716675\n",
      "Epoch : 1 train_step : 734 loss 0.2592732608318329\n",
      "Epoch : 1 train_step : 735 loss 0.22060318291187286\n",
      "Epoch : 1 train_step : 736 loss 0.0452866367995739\n",
      "Epoch : 1 train_step : 737 loss 0.25003567337989807\n",
      "Epoch : 1 train_step : 738 loss 0.04994945228099823\n",
      "Epoch : 1 train_step : 739 loss 0.03995192050933838\n",
      "Epoch : 1 train_step : 740 loss 0.04485463351011276\n",
      "Epoch : 1 train_step : 741 loss 0.07133378833532333\n",
      "Epoch : 1 train_step : 742 loss 0.011663094162940979\n",
      "Epoch : 1 train_step : 743 loss 0.0932963564991951\n",
      "Epoch : 1 train_step : 744 loss 0.1375274956226349\n",
      "Epoch : 1 train_step : 745 loss 0.08730219304561615\n",
      "Epoch : 1 train_step : 746 loss 0.09491138160228729\n",
      "Epoch : 1 train_step : 747 loss 0.05783698707818985\n",
      "Epoch : 1 train_step : 748 loss 0.028841447085142136\n",
      "Epoch : 1 train_step : 749 loss 0.10264608263969421\n",
      "Epoch : 1 train_step : 750 loss 0.009431015700101852\n",
      "Epoch : 1 train_step : 751 loss 0.09457214176654816\n",
      "Epoch : 1 train_step : 752 loss 0.010565406642854214\n",
      "Epoch : 1 train_step : 753 loss 0.03692640736699104\n",
      "Epoch : 1 train_step : 754 loss 0.030281443148851395\n",
      "Epoch : 1 train_step : 755 loss 0.07622252404689789\n",
      "Epoch : 1 train_step : 756 loss 0.05621100589632988\n",
      "Epoch : 1 train_step : 757 loss 0.06779760867357254\n",
      "Epoch : 1 train_step : 758 loss 0.57500821352005\n",
      "Epoch : 1 train_step : 759 loss 0.04920324310660362\n",
      "Epoch : 1 train_step : 760 loss 0.16010193526744843\n",
      "Epoch : 1 train_step : 761 loss 0.0446217879652977\n",
      "Epoch : 1 train_step : 762 loss 0.013057303614914417\n",
      "Epoch : 1 train_step : 763 loss 0.16241556406021118\n",
      "Epoch : 1 train_step : 764 loss 0.1064976155757904\n",
      "Epoch : 1 train_step : 765 loss 0.027918614447116852\n",
      "Epoch : 1 train_step : 766 loss 0.015162788331508636\n",
      "Epoch : 1 train_step : 767 loss 0.010820502415299416\n",
      "Epoch : 1 train_step : 768 loss 0.017546823248267174\n",
      "Epoch : 1 train_step : 769 loss 0.04761352390050888\n",
      "Epoch : 1 train_step : 770 loss 0.2259955257177353\n",
      "Epoch : 1 train_step : 771 loss 0.04246097058057785\n",
      "Epoch : 1 train_step : 772 loss 0.2761434018611908\n",
      "Epoch : 1 train_step : 773 loss 0.48918336629867554\n",
      "Epoch : 1 train_step : 774 loss 0.038137856870889664\n",
      "Epoch : 1 train_step : 775 loss 0.016309896484017372\n",
      "Epoch : 1 train_step : 776 loss 0.16504162549972534\n",
      "Epoch : 1 train_step : 777 loss 0.034842588007450104\n",
      "Epoch : 1 train_step : 778 loss 0.006358026526868343\n",
      "Epoch : 1 train_step : 779 loss 0.06012609228491783\n",
      "Epoch : 1 train_step : 780 loss 0.08121348917484283\n",
      "Epoch : 1 train_step : 781 loss 0.023274708539247513\n",
      "Epoch : 1 train_step : 782 loss 0.14177554845809937\n",
      "Epoch : 1 train_step : 783 loss 0.16116732358932495\n",
      "Epoch : 1 train_step : 784 loss 0.0049826581962406635\n",
      "Epoch : 1 train_step : 785 loss 0.23076829314231873\n",
      "Epoch : 1 train_step : 786 loss 0.1807633638381958\n",
      "Epoch : 1 train_step : 787 loss 0.011892030015587807\n",
      "Epoch : 1 train_step : 788 loss 0.013536766171455383\n",
      "Epoch : 1 train_step : 789 loss 0.15266001224517822\n",
      "Epoch : 1 train_step : 790 loss 0.2911607027053833\n",
      "Epoch : 1 train_step : 791 loss 0.034421760588884354\n",
      "Epoch : 1 train_step : 792 loss 0.023287100717425346\n",
      "Epoch : 1 train_step : 793 loss 0.07469427585601807\n",
      "Epoch : 1 train_step : 794 loss 0.07224434614181519\n",
      "Epoch : 1 train_step : 795 loss 0.041587945073843\n",
      "Epoch : 1 train_step : 796 loss 0.03741900622844696\n",
      "Epoch : 1 train_step : 797 loss 0.02360042929649353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 train_step : 798 loss 0.003616220783442259\n",
      "Epoch : 1 train_step : 799 loss 0.08737194538116455\n",
      "Epoch : 1 train_step : 800 loss 0.10363195836544037\n",
      "Epoch : 1 train_step : 801 loss 0.04589275270700455\n",
      "Epoch : 1 train_step : 802 loss 0.08138065040111542\n",
      "Epoch : 1 train_step : 803 loss 0.021567249670624733\n",
      "Epoch : 1 train_step : 804 loss 0.06605905294418335\n",
      "Epoch : 1 train_step : 805 loss 0.21494199335575104\n",
      "Epoch : 1 train_step : 806 loss 0.02663411572575569\n",
      "Epoch : 1 train_step : 807 loss 0.008951736614108086\n",
      "Epoch : 1 train_step : 808 loss 0.01011657901108265\n",
      "Epoch : 1 train_step : 809 loss 0.060758937150239944\n",
      "Epoch : 1 train_step : 810 loss 0.005547696724534035\n",
      "Epoch : 1 train_step : 811 loss 0.2845669388771057\n",
      "Epoch : 1 train_step : 812 loss 0.010109050199389458\n",
      "Epoch : 1 train_step : 813 loss 0.0013430614490061998\n",
      "Epoch : 1 train_step : 814 loss 0.08317498117685318\n",
      "Epoch : 1 train_step : 815 loss 0.02240198664367199\n",
      "Epoch : 1 train_step : 816 loss 0.011610228568315506\n",
      "Epoch : 1 train_step : 817 loss 0.0068814861588180065\n",
      "Epoch : 1 train_step : 818 loss 0.03495657816529274\n",
      "Epoch : 1 train_step : 819 loss 0.07003290951251984\n",
      "Epoch : 1 train_step : 820 loss 0.006134536117315292\n",
      "Epoch : 1 train_step : 821 loss 0.028484225273132324\n",
      "Epoch : 1 train_step : 822 loss 0.8470068573951721\n",
      "Epoch : 1 train_step : 823 loss 0.09016947448253632\n",
      "Epoch : 1 train_step : 824 loss 1.6327213048934937\n",
      "Epoch : 1 train_step : 825 loss 0.017527053132653236\n",
      "Epoch : 1 train_step : 826 loss 0.07735888659954071\n",
      "Epoch : 1 train_step : 827 loss 0.044047798961400986\n",
      "Epoch : 1 train_step : 828 loss 0.48957359790802\n",
      "Epoch : 1 train_step : 829 loss 0.18854010105133057\n",
      "Epoch : 1 train_step : 830 loss 0.08086004853248596\n",
      "Epoch : 1 train_step : 831 loss 0.21218189597129822\n",
      "Epoch : 1 train_step : 832 loss 0.13571913540363312\n",
      "Epoch : 1 train_step : 833 loss 0.1525202840566635\n",
      "Epoch : 1 train_step : 834 loss 0.057723499834537506\n",
      "Epoch : 1 train_step : 835 loss 0.5319777131080627\n",
      "Epoch : 1 train_step : 836 loss 0.06541616469621658\n",
      "Epoch : 1 train_step : 837 loss 0.05807674676179886\n",
      "Epoch : 1 train_step : 838 loss 0.14555351436138153\n",
      "Epoch : 1 train_step : 839 loss 0.08355028927326202\n",
      "Epoch : 1 train_step : 840 loss 0.19706270098686218\n",
      "Epoch : 1 train_step : 841 loss 0.09834398329257965\n",
      "Epoch : 1 train_step : 842 loss 0.17258106172084808\n",
      "Epoch : 1 train_step : 843 loss 0.2131744623184204\n",
      "Epoch : 1 train_step : 844 loss 0.0310228131711483\n",
      "Epoch : 1 train_step : 845 loss 0.057245030999183655\n",
      "Epoch : 1 train_step : 846 loss 0.04075212404131889\n",
      "Epoch : 1 train_step : 847 loss 1.1336662769317627\n",
      "Epoch : 1 train_step : 848 loss 0.10552485287189484\n",
      "Epoch : 1 train_step : 849 loss 0.06831629574298859\n",
      "Epoch : 1 train_step : 850 loss 0.07622995227575302\n",
      "Epoch : 1 train_step : 851 loss 0.027611814439296722\n",
      "Epoch : 1 train_step : 852 loss 0.08222939074039459\n",
      "Epoch : 1 train_step : 853 loss 0.062090422958135605\n",
      "Epoch : 1 train_step : 854 loss 0.2683817744255066\n",
      "Epoch : 1 train_step : 855 loss 0.14297029376029968\n",
      "Epoch : 1 train_step : 856 loss 0.09730692952871323\n",
      "Epoch : 1 train_step : 857 loss 0.08981317281723022\n",
      "Epoch : 1 train_step : 858 loss 0.2505992650985718\n",
      "Epoch : 1 train_step : 859 loss 0.07630209624767303\n",
      "Epoch : 1 train_step : 860 loss 0.07710395753383636\n",
      "Epoch : 1 train_step : 861 loss 0.10619715601205826\n",
      "Epoch : 1 train_step : 862 loss 0.5718746185302734\n",
      "Epoch : 1 train_step : 863 loss 0.0356772318482399\n",
      "Epoch : 1 train_step : 864 loss 0.07271265983581543\n",
      "Epoch : 1 train_step : 865 loss 0.18035271763801575\n",
      "Epoch : 1 train_step : 866 loss 0.03441132605075836\n",
      "Epoch : 1 train_step : 867 loss 0.07100868970155716\n",
      "Epoch : 1 train_step : 868 loss 0.29164010286331177\n",
      "Epoch : 1 train_step : 869 loss 0.17619282007217407\n",
      "Epoch : 1 train_step : 870 loss 0.053790099918842316\n",
      "Epoch : 1 train_step : 871 loss 0.1972760558128357\n",
      "Epoch : 1 train_step : 872 loss 0.03226073831319809\n",
      "Epoch : 1 train_step : 873 loss 0.07457664608955383\n",
      "Epoch : 1 train_step : 874 loss 0.11952755600214005\n",
      "Epoch : 1 train_step : 875 loss 0.1034543439745903\n",
      "Epoch : 1 train_step : 876 loss 0.06868208199739456\n",
      "Epoch : 1 train_step : 877 loss 0.17433016002178192\n",
      "Epoch : 1 train_step : 878 loss 0.05570679157972336\n",
      "Epoch : 1 train_step : 879 loss 0.1051415354013443\n",
      "Epoch : 1 train_step : 880 loss 0.7075428366661072\n",
      "Epoch : 1 train_step : 881 loss 0.03179043158888817\n",
      "Epoch : 1 train_step : 882 loss 0.022122934460639954\n",
      "Epoch : 1 train_step : 883 loss 0.11357565969228745\n",
      "Epoch : 1 train_step : 884 loss 0.0732998251914978\n",
      "Epoch : 1 train_step : 885 loss 0.06337590515613556\n",
      "Epoch : 1 train_step : 886 loss 0.03600984439253807\n",
      "Epoch : 1 train_step : 887 loss 0.08759455382823944\n",
      "Epoch : 1 train_step : 888 loss 0.07959002256393433\n",
      "Epoch : 1 train_step : 889 loss 0.02996990457177162\n",
      "Epoch : 1 train_step : 890 loss 0.058112964034080505\n",
      "Epoch : 1 train_step : 891 loss 0.07247675955295563\n",
      "Epoch : 1 train_step : 892 loss 2.6880624294281006\n",
      "Epoch : 1 train_step : 893 loss 0.506507158279419\n",
      "Epoch : 1 train_step : 894 loss 0.08359189331531525\n",
      "Epoch : 1 train_step : 895 loss 0.030595218762755394\n",
      "Epoch : 1 train_step : 896 loss 0.12534138560295105\n",
      "Epoch : 1 train_step : 897 loss 0.050071991980075836\n",
      "Epoch : 1 train_step : 898 loss 0.042243000119924545\n",
      "Epoch : 1 train_step : 899 loss 0.32022708654403687\n",
      "Epoch : 1 train_step : 900 loss 0.1298472136259079\n",
      "Epoch : 1 train_step : 901 loss 0.08266124874353409\n",
      "Epoch : 1 train_step : 902 loss 0.1261315941810608\n",
      "Epoch : 1 train_step : 903 loss 0.42532578110694885\n",
      "Epoch : 1 train_step : 904 loss 0.09472331404685974\n",
      "Epoch : 1 train_step : 905 loss 0.07767973840236664\n",
      "Epoch : 1 train_step : 906 loss 0.08814744651317596\n",
      "Epoch : 1 train_step : 907 loss 0.4432353973388672\n",
      "Epoch : 1 train_step : 908 loss 0.07520007342100143\n",
      "Epoch : 1 train_step : 909 loss 0.3254992365837097\n",
      "Epoch : 1 train_step : 910 loss 0.12092006206512451\n",
      "Epoch : 1 train_step : 911 loss 0.108174629509449\n",
      "Epoch : 1 train_step : 912 loss 0.05725148320198059\n",
      "Epoch : 1 train_step : 913 loss 0.07376119494438171\n",
      "Epoch : 1 train_step : 914 loss 0.04019797220826149\n",
      "Epoch : 1 train_step : 915 loss 0.07195574790239334\n",
      "Epoch : 1 train_step : 916 loss 0.06396614015102386\n",
      "Epoch : 1 train_step : 917 loss 0.5418398380279541\n",
      "Epoch : 1 train_step : 918 loss 0.04797966033220291\n",
      "Epoch : 1 train_step : 919 loss 0.08604857325553894\n",
      "Epoch : 1 train_step : 920 loss 0.16638289391994476\n",
      "Epoch : 1 train_step : 921 loss 0.055453889071941376\n",
      "Epoch : 1 train_step : 922 loss 0.14821510016918182\n",
      "Epoch : 1 train_step : 923 loss 0.02725689485669136\n",
      "Epoch : 1 train_step : 924 loss 0.07625073194503784\n",
      "Epoch : 1 train_step : 925 loss 0.0643325075507164\n",
      "Epoch : 1 train_step : 926 loss 0.026420947164297104\n",
      "Epoch : 1 train_step : 927 loss 0.3738090395927429\n",
      "Epoch : 1 train_step : 928 loss 0.2693146765232086\n",
      "Epoch : 1 train_step : 929 loss 0.06349806487560272\n",
      "Epoch : 1 train_step : 930 loss 0.10864561796188354\n",
      "Epoch : 1 train_step : 931 loss 0.0992666557431221\n",
      "Epoch : 1 train_step : 932 loss 0.07106360793113708\n",
      "Epoch : 1 train_step : 933 loss 0.4012410044670105\n",
      "Epoch : 1 train_step : 934 loss 0.049089040607213974\n",
      "Epoch : 1 train_step : 935 loss 0.03964526951313019\n",
      "Epoch : 1 train_step : 936 loss 0.04255584254860878\n",
      "Epoch : 1 train_step : 937 loss 0.018848296254873276\n",
      "Epoch : 1 train_step : 938 loss 0.013126649893820286\n",
      "Epoch : 1 train_step : 939 loss 0.03845679759979248\n",
      "Epoch : 1 train_step : 940 loss 0.027669861912727356\n",
      "Epoch : 1 train_step : 941 loss 0.024566475301980972\n",
      "Epoch : 1 train_step : 942 loss 0.019094858318567276\n",
      "Epoch : 1 train_step : 943 loss 0.010220969095826149\n",
      "Epoch : 1 train_step : 944 loss 0.031175632029771805\n",
      "Epoch : 1 train_step : 945 loss 0.00902287382632494\n",
      "Epoch : 1 train_step : 946 loss 0.07808718830347061\n",
      "Epoch : 1 train_step : 947 loss 0.14597643911838531\n",
      "Epoch : 1 train_step : 948 loss 0.05596686154603958\n",
      "Epoch : 1 train_step : 949 loss 0.04899021238088608\n",
      "Epoch : 1 train_step : 950 loss 0.010520892217755318\n",
      "Epoch : 1 train_step : 951 loss 0.2655746042728424\n",
      "Epoch : 1 train_step : 952 loss 0.027677562087774277\n",
      "Epoch : 1 train_step : 953 loss 0.17473363876342773\n",
      "Epoch : 1 train_step : 954 loss 0.013087636791169643\n",
      "Epoch : 1 train_step : 955 loss 0.020178835839033127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 train_step : 956 loss 0.026305032894015312\n",
      "Epoch : 1 train_step : 957 loss 0.026565998792648315\n",
      "Epoch : 1 train_step : 958 loss 0.0396273136138916\n",
      "Epoch : 1 train_step : 959 loss 0.017594724893569946\n",
      "Epoch : 1 train_step : 960 loss 0.19988110661506653\n",
      "Epoch : 1 train_step : 961 loss 0.039333563297986984\n",
      "Epoch : 1 train_step : 962 loss 0.17646116018295288\n",
      "Epoch : 1 train_step : 963 loss 0.020276255905628204\n",
      "Epoch : 1 train_step : 964 loss 0.02430601790547371\n",
      "Epoch : 1 train_step : 965 loss 0.006425452418625355\n",
      "Epoch : 1 train_step : 966 loss 0.02766931615769863\n",
      "Epoch : 1 train_step : 967 loss 0.013815447688102722\n",
      "Epoch : 1 train_step : 968 loss 0.007137286942452192\n",
      "Epoch : 1 train_step : 969 loss 0.04001873359084129\n",
      "Epoch : 1 train_step : 970 loss 0.0380781926214695\n",
      "Epoch : 1 train_step : 971 loss 0.26026979088783264\n",
      "Epoch : 1 train_step : 972 loss 0.011423974297940731\n",
      "Epoch : 1 train_step : 973 loss 0.050157614052295685\n",
      "Epoch : 1 train_step : 974 loss 0.016107207164168358\n",
      "Epoch : 1 train_step : 975 loss 0.04433772712945938\n",
      "Epoch : 1 train_step : 976 loss 0.2964740991592407\n",
      "Epoch : 1 train_step : 977 loss 0.017615431919693947\n",
      "Epoch : 1 train_step : 978 loss 0.12238059192895889\n",
      "Epoch : 1 train_step : 979 loss 0.04627341032028198\n",
      "Epoch : 1 train_step : 980 loss 0.011577640660107136\n",
      "Epoch : 1 train_step : 981 loss 0.012515062466263771\n",
      "Epoch : 1 train_step : 982 loss 0.07750525325536728\n",
      "Epoch : 1 train_step : 983 loss 0.04373276233673096\n",
      "Epoch : 1 train_step : 984 loss 0.020841779187321663\n",
      "Epoch : 1 train_step : 985 loss 0.013169409707188606\n",
      "Epoch : 1 train_step : 986 loss 0.019524121657013893\n",
      "Epoch : 1 train_step : 987 loss 0.01860557310283184\n",
      "Epoch : 1 train_step : 988 loss 0.09434820711612701\n",
      "Epoch : 1 train_step : 989 loss 0.011414148844778538\n",
      "Epoch : 1 train_step : 990 loss 1.0664201974868774\n",
      "Epoch : 1 train_step : 991 loss 0.016270706430077553\n",
      "Epoch : 1 train_step : 992 loss 0.008757330477237701\n",
      "Epoch : 1 train_step : 993 loss 0.03699812293052673\n",
      "Epoch : 1 train_step : 994 loss 0.04495685175061226\n",
      "Epoch : 1 train_step : 995 loss 0.11642317473888397\n",
      "Epoch : 1 train_step : 996 loss 0.038074247539043427\n",
      "Epoch : 1 train_step : 997 loss 0.10307154059410095\n",
      "Epoch : 1 train_step : 998 loss 0.022447647526860237\n",
      "Epoch : 1 train_step : 999 loss 0.022849414497613907\n",
      "Epoch : 1 train_step : 1000 loss 0.13201811909675598\n",
      "Epoch : 1 train_step : 1001 loss 0.04477018490433693\n",
      "Epoch : 1 train_step : 1002 loss 0.03166847676038742\n",
      "Epoch : 1 train_step : 1003 loss 0.3138324022293091\n",
      "Epoch : 1 train_step : 1004 loss 0.46940797567367554\n",
      "Epoch : 1 train_step : 1005 loss 0.07701820880174637\n",
      "Epoch : 1 train_step : 1006 loss 0.02262340858578682\n",
      "Epoch : 1 train_step : 1007 loss 0.006576284300535917\n",
      "Epoch : 1 train_step : 1008 loss 0.3560482859611511\n",
      "Epoch : 1 train_step : 1009 loss 0.006362231448292732\n",
      "Epoch : 1 train_step : 1010 loss 0.20004390180110931\n",
      "Epoch : 1 train_step : 1011 loss 0.08179698884487152\n",
      "Epoch : 1 train_step : 1012 loss 0.07739260047674179\n",
      "Epoch : 1 train_step : 1013 loss 0.08080492913722992\n",
      "Epoch : 1 train_step : 1014 loss 0.0601835772395134\n",
      "Epoch : 1 train_step : 1015 loss 0.11602836102247238\n",
      "Epoch : 1 train_step : 1016 loss 0.03180988132953644\n",
      "Epoch : 1 train_step : 1017 loss 0.019516684114933014\n",
      "Epoch : 1 train_step : 1018 loss 0.03937578573822975\n",
      "Epoch : 1 train_step : 1019 loss 0.021427899599075317\n",
      "Epoch : 1 train_step : 1020 loss 0.018434667959809303\n",
      "Epoch : 1 train_step : 1021 loss 0.17279061675071716\n",
      "Epoch : 1 train_step : 1022 loss 0.05022266134619713\n",
      "Epoch : 1 train_step : 1023 loss 0.019298110157251358\n",
      "Epoch : 1 train_step : 1024 loss 0.022536447271704674\n",
      "Epoch : 1 train_step : 1025 loss 0.04153997451066971\n",
      "Epoch : 1 train_step : 1026 loss 0.005571167916059494\n",
      "Epoch : 1 train_step : 1027 loss 0.08564102649688721\n",
      "Epoch : 1 train_step : 1028 loss 0.03133486211299896\n",
      "Epoch : 1 train_step : 1029 loss 0.02856910414993763\n",
      "Epoch : 1 train_step : 1030 loss 0.01885596290230751\n",
      "Epoch : 1 train_step : 1031 loss 0.01773308590054512\n",
      "Epoch : 1 train_step : 1032 loss 0.05466528981924057\n",
      "Epoch : 1 train_step : 1033 loss 0.08570248633623123\n",
      "Epoch : 1 train_step : 1034 loss 0.030793119221925735\n",
      "Epoch : 1 train_step : 1035 loss 0.019038792699575424\n",
      "Epoch : 1 train_step : 1036 loss 0.041966427117586136\n",
      "Epoch : 1 train_step : 1037 loss 0.028781699016690254\n",
      "Epoch : 1 train_step : 1038 loss 0.02050376869738102\n",
      "Epoch : 1 train_step : 1039 loss 0.0446196049451828\n",
      "Epoch : 1 train_step : 1040 loss 0.34490692615509033\n",
      "Epoch : 1 train_step : 1041 loss 0.06241988390684128\n",
      "Epoch : 1 train_step : 1042 loss 0.037362705916166306\n",
      "Epoch : 1 train_step : 1043 loss 0.014542875811457634\n",
      "Epoch : 1 train_step : 1044 loss 0.06283137202262878\n",
      "Epoch : 1 train_step : 1045 loss 0.009672463871538639\n",
      "Epoch : 1 train_step : 1046 loss 0.0015886523760855198\n",
      "Epoch : 1 train_step : 1047 loss 0.014151014387607574\n",
      "Epoch : 1 train_step : 1048 loss 0.04366380721330643\n",
      "Epoch : 1 train_step : 1049 loss 0.024393729865550995\n",
      "Epoch : 1 train_step : 1050 loss 0.14939644932746887\n",
      "Epoch : 1 train_step : 1051 loss 0.0009229746065102518\n",
      "Epoch : 1 train_step : 1052 loss 0.11151985824108124\n",
      "Epoch : 1 train_step : 1053 loss 0.1826145499944687\n",
      "Epoch : 1 train_step : 1054 loss 0.007876683957874775\n",
      "Epoch : 1 train_step : 1055 loss 0.013030314818024635\n",
      "Epoch : 1 train_step : 1056 loss 0.004753167275339365\n",
      "Epoch : 1 train_step : 1057 loss 0.023500682786107063\n",
      "Epoch : 1 train_step : 1058 loss 0.1556563526391983\n",
      "Epoch : 1 train_step : 1059 loss 0.01135021448135376\n",
      "Epoch : 1 train_step : 1060 loss 0.06084568426012993\n",
      "Epoch : 1 train_step : 1061 loss 0.01870349980890751\n",
      "Epoch : 1 train_step : 1062 loss 0.277789831161499\n",
      "Epoch : 1 train_step : 1063 loss 0.018523477017879486\n",
      "Epoch : 1 train_step : 1064 loss 0.0010191723704338074\n",
      "Epoch : 1 train_step : 1065 loss 0.07572679966688156\n",
      "Epoch : 1 train_step : 1066 loss 0.0019764837343245745\n",
      "Epoch : 1 train_step : 1067 loss 0.008262244053184986\n",
      "Epoch : 1 train_step : 1068 loss 0.1480165719985962\n",
      "Epoch : 1 train_step : 1069 loss 0.006267750170081854\n",
      "Epoch : 1 train_step : 1070 loss 0.011579448357224464\n",
      "Epoch : 1 train_step : 1071 loss 0.02741602435708046\n",
      "Epoch : 1 train_step : 1072 loss 0.06084218621253967\n",
      "Epoch : 1 train_step : 1073 loss 0.002960455371066928\n",
      "Epoch : 1 train_step : 1074 loss 0.08173144608736038\n",
      "Epoch : 1 train_step : 1075 loss 0.2789630591869354\n",
      "Epoch : 1 train_step : 1076 loss 1.0890979766845703\n",
      "Epoch : 1 train_step : 1077 loss 0.08888363838195801\n",
      "Epoch : 1 train_step : 1078 loss 0.006441712379455566\n",
      "Epoch : 1 train_step : 1079 loss 0.011982973664999008\n",
      "Epoch : 1 train_step : 1080 loss 0.028537768870592117\n",
      "Epoch : 1 train_step : 1081 loss 0.4857122600078583\n",
      "Epoch : 1 train_step : 1082 loss 0.020348303020000458\n",
      "Epoch : 1 train_step : 1083 loss 0.0063096643425524235\n",
      "Epoch : 1 train_step : 1084 loss 0.4923880994319916\n",
      "Epoch : 1 train_step : 1085 loss 0.016764964908361435\n",
      "Epoch : 1 train_step : 1086 loss 0.07203152775764465\n",
      "Epoch : 1 train_step : 1087 loss 0.19083121418952942\n",
      "Epoch : 1 train_step : 1088 loss 0.10433077067136765\n",
      "Epoch : 1 train_step : 1089 loss 0.19636839628219604\n",
      "Epoch : 1 train_step : 1090 loss 0.02270163781940937\n",
      "Epoch : 1 train_step : 1091 loss 0.038956623524427414\n",
      "Epoch : 1 train_step : 1092 loss 0.01163497194647789\n",
      "Epoch : 1 train_step : 1093 loss 0.08681287616491318\n",
      "Epoch : 1 train_step : 1094 loss 0.024289660155773163\n",
      "Epoch : 1 train_step : 1095 loss 0.047362517565488815\n",
      "Epoch : 1 train_step : 1096 loss 0.026188308373093605\n",
      "Epoch : 1 train_step : 1097 loss 0.2659405469894409\n",
      "Epoch : 1 train_step : 1098 loss 0.02668338268995285\n",
      "Epoch : 1 train_step : 1099 loss 0.022713134065270424\n",
      "Epoch : 1 train_step : 1100 loss 0.06620253622531891\n",
      "Epoch : 1 train_step : 1101 loss 0.01506483182311058\n",
      "Epoch : 1 train_step : 1102 loss 0.04545988887548447\n",
      "Epoch : 1 train_step : 1103 loss 0.010102207772433758\n",
      "Epoch : 1 train_step : 1104 loss 0.06421397626399994\n",
      "Epoch : 1 train_step : 1105 loss 0.06350874155759811\n",
      "Epoch : 1 train_step : 1106 loss 0.03019307553768158\n",
      "Epoch : 1 train_step : 1107 loss 0.0038408145774155855\n",
      "Epoch : 1 train_step : 1108 loss 0.042254798114299774\n",
      "Epoch : 1 train_step : 1109 loss 0.006970811635255814\n",
      "Epoch : 1 train_step : 1110 loss 0.03677772730588913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 train_step : 1111 loss 0.018323712050914764\n",
      "Epoch : 1 train_step : 1112 loss 0.019513064995408058\n",
      "Epoch : 1 train_step : 1113 loss 0.01659226417541504\n",
      "Epoch : 1 train_step : 1114 loss 0.09400328993797302\n",
      "Epoch : 1 train_step : 1115 loss 0.02047414891421795\n",
      "Epoch : 1 train_step : 1116 loss 0.007112493738532066\n",
      "Epoch : 1 train_step : 1117 loss 0.012301482260227203\n",
      "Epoch : 1 train_step : 1118 loss 0.03534694388508797\n",
      "Epoch : 1 train_step : 1119 loss 0.0688188374042511\n",
      "Epoch : 1 train_step : 1120 loss 0.4020836055278778\n",
      "Epoch : 1 train_step : 1121 loss 0.030324656516313553\n",
      "Epoch : 1 train_step : 1122 loss 0.02997066266834736\n",
      "Epoch : 1 train_step : 1123 loss 1.1064238548278809\n",
      "Epoch : 1 train_step : 1124 loss 0.016100438311696053\n",
      "Epoch : 1 train_step : 1125 loss 0.04328126832842827\n",
      "Epoch : 1 train_step : 1126 loss 0.13214196264743805\n",
      "Epoch : 1 train_step : 1127 loss 0.15428419411182404\n",
      "Epoch : 1 train_step : 1128 loss 0.007434972561895847\n",
      "Epoch : 1 train_step : 1129 loss 0.04214087128639221\n",
      "Epoch : 1 train_step : 1130 loss 0.03528967499732971\n",
      "Epoch : 1 train_step : 1131 loss 0.09779486060142517\n",
      "Epoch : 1 train_step : 1132 loss 0.30011340975761414\n",
      "Epoch : 1 train_step : 1133 loss 2.296726942062378\n",
      "Epoch : 1 train_step : 1134 loss 0.03551965951919556\n",
      "Epoch : 1 train_step : 1135 loss 0.012704949826002121\n",
      "Epoch : 1 train_step : 1136 loss 0.04738612100481987\n",
      "Epoch : 1 train_step : 1137 loss 0.018945805728435516\n",
      "Epoch : 1 train_step : 1138 loss 0.12593097984790802\n",
      "Epoch : 1 train_step : 1139 loss 0.1616988182067871\n",
      "Epoch : 1 train_step : 1140 loss 0.3619202971458435\n",
      "Epoch : 1 train_step : 1141 loss 0.02446637861430645\n",
      "Epoch : 1 train_step : 1142 loss 0.1303427815437317\n",
      "Epoch : 1 train_step : 1143 loss 0.04080340638756752\n",
      "Epoch : 1 train_step : 1144 loss 0.021322838962078094\n",
      "Epoch : 1 train_step : 1145 loss 0.09983602911233902\n",
      "Epoch : 1 train_step : 1146 loss 0.10129735618829727\n",
      "Epoch : 1 train_step : 1147 loss 0.07130007445812225\n",
      "Epoch : 1 train_step : 1148 loss 0.1757645159959793\n",
      "Epoch : 1 train_step : 1149 loss 0.21037717163562775\n",
      "Epoch : 1 train_step : 1150 loss 0.09414652734994888\n",
      "Epoch : 1 train_step : 1151 loss 0.04802758991718292\n",
      "Epoch : 1 train_step : 1152 loss 0.0534730926156044\n",
      "Epoch : 1 train_step : 1153 loss 0.08872553706169128\n",
      "Epoch : 1 train_step : 1154 loss 0.02816101349890232\n",
      "Epoch : 1 train_step : 1155 loss 0.05073768272995949\n",
      "Epoch : 1 train_step : 1156 loss 0.06953984498977661\n",
      "Epoch : 1 train_step : 1157 loss 0.024606594815850258\n",
      "Epoch : 1 train_step : 1158 loss 0.02233036980032921\n",
      "Epoch : 1 train_step : 1159 loss 0.06053798645734787\n",
      "Epoch : 1 train_step : 1160 loss 0.03530438244342804\n",
      "Epoch : 1 train_step : 1161 loss 0.051162656396627426\n",
      "Epoch : 1 train_step : 1162 loss 0.041791174560785294\n",
      "Epoch : 1 train_step : 1163 loss 0.023918215185403824\n",
      "Epoch : 1 train_step : 1164 loss 0.06542767584323883\n",
      "Epoch : 1 train_step : 1165 loss 0.21252718567848206\n",
      "Epoch : 1 train_step : 1166 loss 0.26095855236053467\n",
      "Epoch : 1 train_step : 1167 loss 0.028904719278216362\n",
      "Epoch : 1 train_step : 1168 loss 0.03637178614735603\n",
      "Epoch : 1 train_step : 1169 loss 0.05233997851610184\n",
      "Epoch : 1 train_step : 1170 loss 0.0382973812520504\n",
      "Epoch : 1 train_step : 1171 loss 0.21366438269615173\n",
      "Epoch : 1 train_step : 1172 loss 0.1469748467206955\n",
      "Epoch : 1 train_step : 1173 loss 1.0382858514785767\n",
      "Epoch : 1 train_step : 1174 loss 0.16629397869110107\n",
      "Epoch : 1 train_step : 1175 loss 0.01419792789965868\n",
      "Epoch : 1 train_step : 1176 loss 0.02742151729762554\n",
      "Epoch : 1 train_step : 1177 loss 1.893074631690979\n",
      "Epoch : 1 train_step : 1178 loss 0.026295632123947144\n",
      "Epoch : 1 train_step : 1179 loss 0.05629643425345421\n",
      "Epoch : 1 train_step : 1180 loss 0.03618757426738739\n",
      "Epoch : 1 train_step : 1181 loss 0.032824523746967316\n",
      "Epoch : 1 train_step : 1182 loss 0.13876259326934814\n",
      "Epoch : 1 train_step : 1183 loss 0.1244996190071106\n",
      "Epoch : 1 train_step : 1184 loss 0.14437346160411835\n",
      "Epoch : 1 train_step : 1185 loss 0.8446546196937561\n",
      "Epoch : 1 train_step : 1186 loss 0.13154880702495575\n",
      "Epoch : 1 train_step : 1187 loss 0.11540724337100983\n",
      "Epoch : 1 train_step : 1188 loss 0.08324748277664185\n",
      "Epoch : 1 train_step : 1189 loss 0.07840423285961151\n",
      "Epoch : 1 train_step : 1190 loss 0.13195137679576874\n",
      "Epoch : 1 train_step : 1191 loss 0.06894011050462723\n",
      "Epoch : 1 train_step : 1192 loss 0.1399843543767929\n",
      "Epoch : 1 train_step : 1193 loss 0.10319559276103973\n",
      "Epoch : 1 train_step : 1194 loss 0.08270859718322754\n",
      "Epoch : 1 train_step : 1195 loss 0.06461553275585175\n",
      "Epoch : 1 train_step : 1196 loss 0.054089851677417755\n",
      "Epoch : 1 train_step : 1197 loss 0.19108644127845764\n",
      "Epoch : 1 train_step : 1198 loss 0.11137321591377258\n",
      "Epoch : 1 train_step : 1199 loss 0.10914670675992966\n",
      "Epoch : 1 train_step : 1200 loss 0.08815079927444458\n",
      "Epoch : 1 train_step : 1201 loss 0.16814841330051422\n",
      "Epoch : 1 train_step : 1202 loss 0.2573980987071991\n",
      "Epoch : 1 train_step : 1203 loss 0.07275620102882385\n",
      "Epoch : 1 train_step : 1204 loss 0.03403094410896301\n",
      "Epoch : 1 train_step : 1205 loss 0.021795017644762993\n",
      "Epoch : 1 train_step : 1206 loss 0.3926585018634796\n",
      "Epoch : 1 train_step : 1207 loss 0.07689893990755081\n",
      "Epoch : 1 train_step : 1208 loss 0.029170654714107513\n",
      "Epoch : 1 train_step : 1209 loss 0.05910267308354378\n",
      "Epoch : 1 train_step : 1210 loss 0.09564302861690521\n",
      "Epoch : 1 train_step : 1211 loss 0.11436590552330017\n",
      "Epoch : 1 train_step : 1212 loss 0.06630727648735046\n",
      "Epoch : 1 train_step : 1213 loss 0.04503421112895012\n",
      "Epoch : 1 train_step : 1214 loss 0.03863707557320595\n",
      "Epoch : 1 train_step : 1215 loss 0.026791632175445557\n",
      "Epoch : 1 train_step : 1216 loss 0.023679077625274658\n",
      "Epoch : 1 train_step : 1217 loss 0.048957157880067825\n",
      "Epoch : 1 train_step : 1218 loss 0.025822926312685013\n",
      "Epoch : 1 train_step : 1219 loss 0.06664998084306717\n",
      "Epoch : 1 train_step : 1220 loss 0.04638581722974777\n",
      "Epoch : 1 train_step : 1221 loss 0.07291513681411743\n",
      "Epoch : 1 train_step : 1222 loss 0.004647472873330116\n",
      "Epoch : 1 train_step : 1223 loss 0.021166447550058365\n",
      "Epoch : 1 train_step : 1224 loss 0.042239829897880554\n",
      "Epoch : 1 train_step : 1225 loss 0.031111476942896843\n",
      "Epoch : 1 train_step : 1226 loss 0.13868822157382965\n",
      "Epoch : 1 train_step : 1227 loss 0.011031866073608398\n",
      "Epoch : 1 train_step : 1228 loss 0.043453339487314224\n",
      "Epoch : 1 train_step : 1229 loss 0.05708969384431839\n",
      "Epoch : 1 train_step : 1230 loss 0.023895546793937683\n",
      "Epoch : 1 train_step : 1231 loss 0.024270830675959587\n",
      "Epoch : 1 train_step : 1232 loss 0.005044814199209213\n",
      "Epoch : 1 train_step : 1233 loss 0.022394487634301186\n",
      "Epoch : 1 train_step : 1234 loss 0.033179618418216705\n",
      "Epoch : 1 train_step : 1235 loss 0.0290220994502306\n",
      "Epoch : 1 train_step : 1236 loss 0.0272790789604187\n",
      "Epoch : 1 train_step : 1237 loss 0.0293806791305542\n",
      "Epoch : 1 train_step : 1238 loss 0.03190968185663223\n",
      "Epoch : 1 train_step : 1239 loss 0.023388464003801346\n",
      "Epoch : 1 train_step : 1240 loss 0.21822644770145416\n",
      "Epoch : 1 train_step : 1241 loss 0.044266603887081146\n",
      "Epoch : 1 train_step : 1242 loss 0.02578006684780121\n",
      "Epoch : 1 train_step : 1243 loss 0.008256889879703522\n",
      "Epoch : 1 train_step : 1244 loss 0.020139312371611595\n",
      "Epoch : 1 train_step : 1245 loss 0.00400561885908246\n",
      "Epoch : 1 train_step : 1246 loss 0.08848363161087036\n",
      "Epoch : 1 train_step : 1247 loss 0.023571090772747993\n",
      "Epoch : 1 train_step : 1248 loss 0.00572860985994339\n",
      "Epoch : 1 train_step : 1249 loss 0.09659083932638168\n",
      "Epoch : 1 train_step : 1250 loss 0.019420038908720016\n",
      "Epoch : 1 train_step : 1251 loss 0.001416329643689096\n",
      "Epoch : 1 train_step : 1252 loss 0.9425574541091919\n",
      "Epoch : 1 train_step : 1253 loss 0.0188290998339653\n",
      "Epoch : 1 train_step : 1254 loss 1.3295503854751587\n",
      "Epoch : 1 train_step : 1255 loss 0.665010392665863\n",
      "Epoch : 1 train_step : 1256 loss 0.006149631459265947\n",
      "Epoch : 1 train_step : 1257 loss 0.07447022944688797\n",
      "Epoch : 1 train_step : 1258 loss 0.005641586147248745\n",
      "Epoch : 1 train_step : 1259 loss 0.23111791908740997\n",
      "Epoch : 1 train_step : 1260 loss 0.03508753702044487\n",
      "Epoch : 1 train_step : 1261 loss 0.33904051780700684\n",
      "Epoch : 1 train_step : 1262 loss 0.08535870909690857\n",
      "Epoch : 1 train_step : 1263 loss 0.0718555748462677\n",
      "Epoch : 1 train_step : 1264 loss 0.11195479333400726\n",
      "Epoch : 1 train_step : 1265 loss 0.11511679738759995\n",
      "Epoch : 1 train_step : 1266 loss 0.14342088997364044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 train_step : 1267 loss 0.07505740225315094\n",
      "Epoch : 1 train_step : 1268 loss 0.05505293607711792\n",
      "Epoch : 1 train_step : 1269 loss 0.09212511777877808\n",
      "Epoch : 1 train_step : 1270 loss 0.24057507514953613\n",
      "Epoch : 1 train_step : 1271 loss 0.14619924128055573\n",
      "Epoch : 1 train_step : 1272 loss 0.2462308704853058\n",
      "Epoch : 1 train_step : 1273 loss 0.09373483061790466\n",
      "Epoch : 1 train_step : 1274 loss 1.0626380443572998\n",
      "Epoch : 1 train_step : 1275 loss 0.17573510110378265\n",
      "Epoch : 1 train_step : 1276 loss 0.29539796710014343\n",
      "Epoch : 1 train_step : 1277 loss 0.12281665205955505\n",
      "Epoch : 1 train_step : 1278 loss 0.15572276711463928\n",
      "Epoch : 1 train_step : 1279 loss 0.21543052792549133\n",
      "Epoch : 1 train_step : 1280 loss 0.06194367632269859\n",
      "Epoch : 1 train_step : 1281 loss 0.09732289612293243\n",
      "Epoch : 1 train_step : 1282 loss 0.04386662319302559\n",
      "Epoch : 1 train_step : 1283 loss 0.05199848487973213\n",
      "Epoch : 1 train_step : 1284 loss 0.017002515494823456\n",
      "Epoch : 1 train_step : 1285 loss 0.06396022439002991\n",
      "Epoch : 1 train_step : 1286 loss 0.07791586220264435\n",
      "Epoch : 1 train_step : 1287 loss 0.025257589295506477\n",
      "Epoch : 1 train_step : 1288 loss 0.09770655632019043\n",
      "Epoch : 1 train_step : 1289 loss 0.0474558100104332\n",
      "Epoch : 1 train_step : 1290 loss 0.26413494348526\n",
      "Epoch : 1 train_step : 1291 loss 0.1780901849269867\n",
      "Epoch : 1 train_step : 1292 loss 0.05483107641339302\n",
      "Epoch : 1 train_step : 1293 loss 0.639644205570221\n",
      "Epoch : 1 train_step : 1294 loss 0.04145330935716629\n",
      "Epoch : 1 train_step : 1295 loss 0.058598682284355164\n",
      "Epoch : 1 train_step : 1296 loss 0.018008124083280563\n",
      "Epoch : 1 train_step : 1297 loss 0.009505566209554672\n",
      "Epoch : 1 train_step : 1298 loss 0.01738400012254715\n",
      "Epoch : 1 train_step : 1299 loss 0.020698297768831253\n",
      "Epoch : 1 train_step : 1300 loss 0.1707991510629654\n",
      "Epoch : 1 train_step : 1301 loss 0.07490943372249603\n",
      "Epoch : 1 train_step : 1302 loss 0.032420650124549866\n",
      "Epoch : 1 train_step : 1303 loss 0.04550420492887497\n",
      "Epoch : 1 train_step : 1304 loss 0.04614148661494255\n",
      "Epoch : 1 train_step : 1305 loss 0.04346056655049324\n",
      "Epoch : 1 train_step : 1306 loss 0.01932154782116413\n",
      "Epoch : 1 train_step : 1307 loss 0.023189054802060127\n",
      "Epoch : 1 train_step : 1308 loss 0.14842014014720917\n",
      "Epoch : 1 train_step : 1309 loss 0.06804677844047546\n",
      "Epoch : 1 train_step : 1310 loss 0.029915422201156616\n",
      "Epoch : 1 train_step : 1311 loss 0.015414739958941936\n",
      "Epoch : 1 train_step : 1312 loss 0.014392746612429619\n",
      "Epoch : 1 train_step : 1313 loss 0.08815181255340576\n",
      "Epoch : 1 train_step : 1314 loss 0.2582315504550934\n",
      "Epoch : 1 train_step : 1315 loss 0.6067987084388733\n",
      "Epoch : 1 train_step : 1316 loss 0.02538231760263443\n",
      "Epoch : 1 train_step : 1317 loss 0.030427513644099236\n",
      "Epoch : 1 train_step : 1318 loss 0.027195431292057037\n",
      "Epoch : 1 train_step : 1319 loss 0.14392614364624023\n",
      "Epoch : 1 train_step : 1320 loss 0.01893208734691143\n",
      "Epoch : 1 train_step : 1321 loss 0.00939551368355751\n",
      "Epoch : 1 train_step : 1322 loss 0.6633784770965576\n",
      "Epoch : 1 train_step : 1323 loss 0.015138302929699421\n",
      "Epoch : 1 train_step : 1324 loss 0.1035662591457367\n",
      "Epoch : 1 train_step : 1325 loss 0.04471276327967644\n",
      "Epoch : 1 train_step : 1326 loss 0.01625276729464531\n",
      "Epoch : 1 train_step : 1327 loss 0.12153934687376022\n",
      "Epoch : 1 train_step : 1328 loss 0.008990373462438583\n",
      "Epoch : 1 train_step : 1329 loss 0.02550068497657776\n",
      "Epoch : 1 train_step : 1330 loss 0.11850797384977341\n",
      "Epoch : 1 train_step : 1331 loss 0.01590617559850216\n",
      "Epoch : 1 train_step : 1332 loss 0.045062363147735596\n",
      "Epoch : 1 train_step : 1333 loss 0.03946463391184807\n",
      "Epoch : 1 train_step : 1334 loss 1.117503046989441\n",
      "Epoch : 1 train_step : 1335 loss 0.1200282871723175\n",
      "Epoch : 1 train_step : 1336 loss 0.13345691561698914\n",
      "Epoch : 1 train_step : 1337 loss 0.03900358825922012\n",
      "Epoch : 1 train_step : 1338 loss 0.08280710130929947\n",
      "Epoch : 1 train_step : 1339 loss 0.15507562458515167\n",
      "Epoch : 1 train_step : 1340 loss 0.08276896178722382\n",
      "Epoch : 1 train_step : 1341 loss 0.03870892524719238\n",
      "Epoch : 1 train_step : 1342 loss 0.05350496619939804\n",
      "Epoch : 1 train_step : 1343 loss 0.05190381407737732\n",
      "Epoch : 1 train_step : 1344 loss 0.16606132686138153\n",
      "Epoch : 1 train_step : 1345 loss 0.023038536310195923\n",
      "Epoch : 1 train_step : 1346 loss 0.7029621601104736\n",
      "Epoch : 1 train_step : 1347 loss 0.03484175726771355\n",
      "Epoch : 1 train_step : 1348 loss 0.06034906953573227\n",
      "Epoch : 1 train_step : 1349 loss 0.08090473711490631\n",
      "Epoch : 1 train_step : 1350 loss 0.11061303317546844\n",
      "Epoch : 1 train_step : 1351 loss 0.07636310160160065\n",
      "Epoch : 1 train_step : 1352 loss 0.03170553594827652\n",
      "Epoch : 1 train_step : 1353 loss 0.09327666461467743\n",
      "Epoch : 1 train_step : 1354 loss 0.1558234542608261\n",
      "Epoch : 1 train_step : 1355 loss 0.04110589250922203\n",
      "Epoch : 1 train_step : 1356 loss 0.41854968667030334\n",
      "Epoch : 1 train_step : 1357 loss 1.7995432615280151\n",
      "Epoch : 1 train_step : 1358 loss 0.08524558693170547\n",
      "Epoch : 1 train_step : 1359 loss 0.07959868013858795\n",
      "Epoch : 1 train_step : 1360 loss 0.051264554262161255\n",
      "Epoch : 1 train_step : 1361 loss 0.04969051480293274\n",
      "Epoch : 1 train_step : 1362 loss 0.042339786887168884\n",
      "Epoch : 1 train_step : 1363 loss 0.11628368496894836\n",
      "Epoch : 1 train_step : 1364 loss 0.07921135425567627\n",
      "Epoch : 1 train_step : 1365 loss 0.18265727162361145\n",
      "Epoch : 1 train_step : 1366 loss 0.06871294975280762\n",
      "Epoch : 1 train_step : 1367 loss 0.1365269273519516\n",
      "Epoch : 1 train_step : 1368 loss 0.796221137046814\n",
      "Epoch : 1 train_step : 1369 loss 0.0828634575009346\n",
      "Epoch : 1 train_step : 1370 loss 0.05958419665694237\n",
      "Epoch : 1 train_step : 1371 loss 0.07009859383106232\n",
      "Epoch : 1 train_step : 1372 loss 0.09174512326717377\n",
      "Epoch : 1 train_step : 1373 loss 0.5605790615081787\n",
      "Epoch : 1 train_step : 1374 loss 0.07605800777673721\n",
      "Epoch : 1 train_step : 1375 loss 0.1298959106206894\n",
      "Epoch : 1 train_step : 1376 loss 0.06981974840164185\n",
      "Epoch : 1 train_step : 1377 loss 0.051139503717422485\n",
      "Epoch : 1 train_step : 1378 loss 0.055938445031642914\n",
      "Epoch : 1 train_step : 1379 loss 0.03848031163215637\n",
      "Epoch : 1 train_step : 1380 loss 0.050173766911029816\n",
      "Epoch : 1 train_step : 1381 loss 0.05842754617333412\n",
      "Epoch : 1 train_step : 1382 loss 0.09886882454156876\n",
      "Epoch : 1 train_step : 1383 loss 0.06759867072105408\n",
      "Epoch : 1 train_step : 1384 loss 0.04394752159714699\n",
      "Epoch : 1 train_step : 1385 loss 0.25228917598724365\n",
      "Epoch : 1 train_step : 1386 loss 0.07804277539253235\n",
      "Epoch : 1 train_step : 1387 loss 0.22804994881153107\n",
      "Epoch : 1 train_step : 1388 loss 0.05211091786623001\n",
      "Epoch : 1 train_step : 1389 loss 0.20021843910217285\n",
      "Epoch : 1 train_step : 1390 loss 0.022490033879876137\n",
      "Epoch : 1 train_step : 1391 loss 0.32583701610565186\n",
      "Epoch : 1 train_step : 1392 loss 0.06128973886370659\n",
      "Epoch : 1 train_step : 1393 loss 0.1455196738243103\n",
      "Epoch : 1 train_step : 1394 loss 0.2588437795639038\n",
      "Epoch : 1 train_step : 1395 loss 0.06328648328781128\n",
      "Epoch : 1 train_step : 1396 loss 0.0539814755320549\n",
      "Epoch : 1 train_step : 1397 loss 0.044259075075387955\n",
      "Epoch : 1 train_step : 1398 loss 0.04645496979355812\n",
      "Epoch : 1 train_step : 1399 loss 0.5810547471046448\n",
      "Epoch : 1 train_step : 1400 loss 0.10846735537052155\n",
      "Epoch : 1 train_step : 1401 loss 0.027912989258766174\n",
      "Epoch : 1 train_step : 1402 loss 0.049806322902441025\n",
      "Epoch : 1 train_step : 1403 loss 0.07340335845947266\n",
      "Epoch : 1 train_step : 1404 loss 0.04112153872847557\n",
      "Epoch : 1 train_step : 1405 loss 0.11737458407878876\n",
      "Epoch : 1 train_step : 1406 loss 0.02257392555475235\n",
      "Epoch : 1 train_step : 1407 loss 0.02687086910009384\n",
      "Epoch : 1 train_step : 1408 loss 0.10688288509845734\n",
      "Epoch : 1 train_step : 1409 loss 0.3420940041542053\n",
      "Epoch : 1 train_step : 1410 loss 0.0200200192630291\n",
      "Epoch : 1 train_step : 1411 loss 0.04764742776751518\n",
      "Epoch : 1 train_step : 1412 loss 0.22720131278038025\n",
      "Epoch : 1 train_step : 1413 loss 0.008559122681617737\n",
      "Epoch : 1 train_step : 1414 loss 0.01698721945285797\n",
      "Epoch : 1 train_step : 1415 loss 0.046327847987413406\n",
      "Epoch : 1 train_step : 1416 loss 0.024792075157165527\n",
      "Epoch : 1 train_step : 1417 loss 0.15431106090545654\n",
      "Epoch : 1 train_step : 1418 loss 0.03827161714434624\n",
      "Epoch : 1 train_step : 1419 loss 0.13900035619735718\n",
      "Epoch : 1 train_step : 1420 loss 0.03603830561041832\n",
      "Epoch : 1 train_step : 1421 loss 0.03143250569701195\n",
      "Epoch : 1 train_step : 1422 loss 0.02720441296696663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 train_step : 1423 loss 0.08823364973068237\n",
      "Epoch : 1 train_step : 1424 loss 0.03282708674669266\n",
      "Epoch : 1 train_step : 1425 loss 0.03582377731800079\n",
      "Epoch : 1 train_step : 1426 loss 0.192159041762352\n",
      "Epoch : 1 train_step : 1427 loss 0.046393021941185\n",
      "Epoch : 1 train_step : 1428 loss 0.026637164875864983\n",
      "Epoch : 1 train_step : 1429 loss 0.05395595356822014\n",
      "Epoch : 1 train_step : 1430 loss 0.03560926765203476\n",
      "Epoch : 1 train_step : 1431 loss 0.005846941377967596\n",
      "Epoch : 1 train_step : 1432 loss 0.237813800573349\n",
      "Epoch : 1 train_step : 1433 loss 0.010227270424365997\n",
      "Epoch : 1 train_step : 1434 loss 0.08959042280912399\n",
      "Epoch : 1 train_step : 1435 loss 0.14167536795139313\n",
      "Epoch : 1 train_step : 1436 loss 0.004629668779671192\n",
      "Epoch : 1 train_step : 1437 loss 0.012524669989943504\n",
      "Epoch : 1 train_step : 1438 loss 0.035988908261060715\n",
      "Epoch : 1 train_step : 1439 loss 0.041701167821884155\n",
      "Epoch : 1 train_step : 1440 loss 0.09300658106803894\n",
      "Epoch : 1 train_step : 1441 loss 0.08688066899776459\n",
      "Epoch : 1 train_step : 1442 loss 0.05380105599761009\n",
      "Epoch : 1 train_step : 1443 loss 0.04007662832736969\n",
      "Epoch : 1 train_step : 1444 loss 0.2465900182723999\n",
      "Epoch : 1 train_step : 1445 loss 0.0244508795440197\n",
      "Epoch : 1 train_step : 1446 loss 1.0598043203353882\n",
      "Epoch : 1 train_step : 1447 loss 0.1587364226579666\n",
      "Epoch : 1 train_step : 1448 loss 0.0691894143819809\n",
      "Epoch : 1 train_step : 1449 loss 0.04256673902273178\n",
      "Epoch : 1 train_step : 1450 loss 0.019242417067289352\n",
      "Epoch : 1 train_step : 1451 loss 0.09504872560501099\n",
      "Epoch : 1 train_step : 1452 loss 0.06586839258670807\n",
      "Epoch : 1 train_step : 1453 loss 0.0736309215426445\n",
      "Epoch : 1 train_step : 1454 loss 0.08136232197284698\n",
      "Epoch : 1 train_step : 1455 loss 0.3750024437904358\n",
      "Epoch : 1 train_step : 1456 loss 0.05263194441795349\n",
      "Epoch : 1 train_step : 1457 loss 0.0384502112865448\n",
      "Epoch : 1 train_step : 1458 loss 0.02881656214594841\n",
      "Epoch : 1 train_step : 1459 loss 0.1143011525273323\n",
      "Epoch : 1 train_step : 1460 loss 0.05148257315158844\n",
      "Epoch : 1 train_step : 1461 loss 0.1319117546081543\n",
      "Epoch : 1 train_step : 1462 loss 0.11550883948802948\n",
      "Epoch : 1 train_step : 1463 loss 0.019987354055047035\n",
      "Epoch : 1 train_step : 1464 loss 0.07489842921495438\n",
      "Epoch : 1 train_step : 1465 loss 0.017322558909654617\n",
      "Epoch : 1 train_step : 1466 loss 0.04903598129749298\n",
      "Epoch : 1 train_step : 1467 loss 0.05943853408098221\n",
      "Epoch : 1 train_step : 1468 loss 0.7716690897941589\n",
      "Epoch : 1 train_step : 1469 loss 0.04148130118846893\n",
      "Epoch : 1 train_step : 1470 loss 0.0362287275493145\n",
      "Epoch : 1 train_step : 1471 loss 0.14346688985824585\n",
      "Epoch : 1 train_step : 1472 loss 0.02642950601875782\n",
      "Epoch : 1 train_step : 1473 loss 0.06183962523937225\n",
      "Epoch : 1 train_step : 1474 loss 0.019600477069616318\n",
      "Epoch : 1 train_step : 1475 loss 0.03456161543726921\n",
      "Epoch : 1 train_step : 1476 loss 0.012174949049949646\n",
      "Epoch : 1 train_step : 1477 loss 0.0339658260345459\n",
      "Epoch : 1 train_step : 1478 loss 0.0411025770008564\n",
      "Epoch : 1 train_step : 1479 loss 0.009964673779904842\n",
      "Epoch : 1 train_step : 1480 loss 0.0840953066945076\n",
      "Epoch : 1 train_step : 1481 loss 0.073182612657547\n",
      "Epoch : 1 train_step : 1482 loss 0.012044309638440609\n",
      "Epoch : 1 train_step : 1483 loss 0.03202225640416145\n",
      "Epoch : 1 train_step : 1484 loss 0.01762133650481701\n",
      "Epoch : 1 train_step : 1485 loss 0.32623913884162903\n",
      "Epoch : 1 train_step : 1486 loss 0.020651299506425858\n",
      "Epoch : 1 train_step : 1487 loss 0.03177885711193085\n",
      "Epoch : 1 train_step : 1488 loss 0.013339393772184849\n",
      "Epoch : 1 train_step : 1489 loss 0.07572589814662933\n",
      "Epoch : 1 train_step : 1490 loss 0.02970128320157528\n",
      "Epoch : 1 train_step : 1491 loss 1.633722186088562\n",
      "Epoch : 1 train_step : 1492 loss 0.06597565859556198\n",
      "Epoch : 1 train_step : 1493 loss 0.06797143071889877\n",
      "Epoch : 1 train_step : 1494 loss 0.028865426778793335\n",
      "Epoch : 1 train_step : 1495 loss 0.03705478832125664\n",
      "Epoch : 1 train_step : 1496 loss 0.02209668606519699\n",
      "Epoch : 1 train_step : 1497 loss 0.10208714753389359\n",
      "Epoch : 1 train_step : 1498 loss 0.11594422161579132\n",
      "Epoch : 1 train_step : 1499 loss 0.2441130429506302\n",
      "Epoch : 1 train_step : 1500 loss 0.556472659111023\n",
      "Epoch : 1 train_step : 1501 loss 0.1267436146736145\n",
      "Epoch : 1 train_step : 1502 loss 0.24688103795051575\n",
      "Epoch : 1 train_step : 1503 loss 0.06208474561572075\n",
      "Epoch : 1 train_step : 1504 loss 0.3296789228916168\n",
      "Epoch : 1 train_step : 1505 loss 0.04085373133420944\n",
      "Epoch : 1 train_step : 1506 loss 0.045432280749082565\n",
      "Epoch : 1 train_step : 1507 loss 0.08525782823562622\n",
      "Epoch : 1 train_step : 1508 loss 0.13037514686584473\n",
      "Epoch : 1 train_step : 1509 loss 0.38631340861320496\n",
      "Epoch : 1 train_step : 1510 loss 0.25078627467155457\n",
      "Epoch : 1 train_step : 1511 loss 0.08276593685150146\n",
      "Epoch : 1 train_step : 1512 loss 0.219228595495224\n",
      "Epoch : 1 train_step : 1513 loss 0.0915108174085617\n",
      "Epoch : 1 train_step : 1514 loss 0.11016817390918732\n",
      "Epoch : 1 train_step : 1515 loss 0.11582115292549133\n",
      "Epoch : 1 train_step : 1516 loss 0.07845588028430939\n",
      "Epoch : 1 train_step : 1517 loss 0.10579977929592133\n",
      "Epoch : 1 train_step : 1518 loss 0.040059320628643036\n",
      "Epoch : 1 train_step : 1519 loss 0.05403320491313934\n",
      "Epoch : 1 train_step : 1520 loss 0.04654219374060631\n",
      "Epoch : 1 train_step : 1521 loss 0.07188201695680618\n",
      "Epoch : 1 train_step : 1522 loss 0.09775882214307785\n",
      "Epoch : 1 train_step : 1523 loss 0.07793345302343369\n",
      "Epoch : 1 train_step : 1524 loss 0.028976241126656532\n",
      "Epoch : 1 train_step : 1525 loss 0.06342169642448425\n",
      "Epoch : 1 train_step : 1526 loss 0.07724641263484955\n",
      "Epoch : 1 train_step : 1527 loss 0.10972992330789566\n",
      "Epoch : 1 train_step : 1528 loss 0.13852658867835999\n",
      "Epoch : 1 train_step : 1529 loss 0.07270803302526474\n",
      "Epoch : 1 train_step : 1530 loss 0.021499846130609512\n",
      "Epoch : 1 train_step : 1531 loss 0.05672894045710564\n",
      "Epoch : 1 train_step : 1532 loss 0.039961978793144226\n",
      "Epoch : 1 train_step : 1533 loss 0.03722293674945831\n",
      "Epoch : 1 train_step : 1534 loss 0.10418963432312012\n",
      "Epoch : 1 train_step : 1535 loss 0.027504030615091324\n",
      "Epoch : 1 train_step : 1536 loss 0.14624375104904175\n",
      "Epoch : 1 train_step : 1537 loss 0.021849926561117172\n",
      "Epoch : 1 train_step : 1538 loss 0.04972992092370987\n",
      "Epoch : 1 train_step : 1539 loss 0.03760220855474472\n",
      "Epoch : 1 train_step : 1540 loss 0.04420189559459686\n",
      "Epoch : 1 train_step : 1541 loss 0.07411259412765503\n",
      "Epoch : 1 train_step : 1542 loss 0.031335990875959396\n",
      "Epoch : 1 train_step : 1543 loss 1.0398411750793457\n",
      "Epoch : 1 train_step : 1544 loss 0.07268697023391724\n",
      "Epoch : 1 train_step : 1545 loss 0.023962024599313736\n",
      "Epoch : 1 train_step : 1546 loss 0.03476998209953308\n",
      "Epoch : 1 train_step : 1547 loss 0.030396979302167892\n",
      "Epoch : 1 train_step : 1548 loss 0.02951229363679886\n",
      "Epoch : 1 train_step : 1549 loss 0.06567567586898804\n",
      "Epoch : 1 train_step : 1550 loss 0.012491781264543533\n",
      "Epoch : 1 train_step : 1551 loss 0.17949938774108887\n",
      "Epoch : 1 train_step : 1552 loss 0.18692047894001007\n",
      "Epoch : 1 train_step : 1553 loss 0.039000459015369415\n",
      "Epoch : 1 train_step : 1554 loss 0.031237728893756866\n",
      "Epoch : 1 train_step : 1555 loss 0.01360340602695942\n",
      "Epoch : 1 train_step : 1556 loss 0.023447534069418907\n",
      "Epoch : 1 train_step : 1557 loss 0.03851953148841858\n",
      "Epoch : 1 train_step : 1558 loss 0.21085326373577118\n",
      "Epoch : 1 train_step : 1559 loss 0.04989822581410408\n",
      "Epoch : 1 train_step : 1560 loss 0.05979369953274727\n",
      "Epoch : 1 train_step : 1561 loss 0.31396427750587463\n",
      "Epoch : 1 train_step : 1562 loss 0.15269404649734497\n",
      "Epoch : 1 train_step : 1563 loss 0.06915342062711716\n",
      "Epoch : 1 train_step : 1564 loss 0.030720047652721405\n",
      "Epoch : 1 train_step : 1565 loss 0.06324467062950134\n",
      "Epoch : 1 train_step : 1566 loss 0.13515494763851166\n",
      "Epoch : 1 train_step : 1567 loss 0.04578620567917824\n",
      "Epoch : 1 train_step : 1568 loss 0.22398991882801056\n",
      "Epoch : 1 train_step : 1569 loss 0.06530147045850754\n",
      "Epoch : 1 train_step : 1570 loss 0.02821008488535881\n",
      "Epoch : 1 train_step : 1571 loss 0.053206667304039\n",
      "Epoch : 1 train_step : 1572 loss 0.06082400307059288\n",
      "Epoch : 1 train_step : 1573 loss 0.07303890585899353\n",
      "Epoch : 1 train_step : 1574 loss 0.5136749148368835\n",
      "Epoch : 1 train_step : 1575 loss 0.10481733828783035\n",
      "Epoch : 1 train_step : 1576 loss 0.010482769459486008\n",
      "Epoch : 1 train_step : 1577 loss 0.11344625800848007\n",
      "Epoch : 1 train_step : 1578 loss 0.05010640621185303\n",
      "Epoch : 1 train_step : 1579 loss 0.32692551612854004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 train_step : 1580 loss 0.11132371425628662\n",
      "Epoch : 1 train_step : 1581 loss 0.05687422305345535\n",
      "Epoch : 1 train_step : 1582 loss 0.011217039078474045\n",
      "Epoch : 1 train_step : 1583 loss 0.030240967869758606\n",
      "Epoch : 1 train_step : 1584 loss 0.10810273140668869\n",
      "Epoch : 1 train_step : 1585 loss 0.08185477554798126\n",
      "Epoch : 1 train_step : 1586 loss 0.011033228598535061\n",
      "Epoch : 1 train_step : 1587 loss 0.004998181946575642\n",
      "Epoch : 1 train_step : 1588 loss 0.03828493505716324\n",
      "Epoch : 1 train_step : 1589 loss 0.6459649801254272\n",
      "Epoch : 1 train_step : 1590 loss 1.2917513847351074\n",
      "Epoch : 1 train_step : 1591 loss 0.17226532101631165\n",
      "Epoch : 1 train_step : 1592 loss 0.13934963941574097\n",
      "Epoch : 1 train_step : 1593 loss 0.029427126049995422\n",
      "Epoch : 1 train_step : 1594 loss 0.02637207880616188\n",
      "Epoch : 1 train_step : 1595 loss 0.14092889428138733\n",
      "Epoch : 1 train_step : 1596 loss 0.5406286120414734\n",
      "Epoch : 1 train_step : 1597 loss 0.0526638962328434\n",
      "Epoch : 1 train_step : 1598 loss 0.05451309308409691\n",
      "Epoch : 1 train_step : 1599 loss 0.09512194991111755\n",
      "Epoch : 1 train_step : 1600 loss 0.2232864797115326\n",
      "Epoch : 1 train_step : 1601 loss 0.12480460107326508\n",
      "Epoch : 1 train_step : 1602 loss 0.09995684027671814\n",
      "Epoch : 1 train_step : 1603 loss 0.08148771524429321\n",
      "Epoch : 1 train_step : 1604 loss 0.6351449489593506\n",
      "Epoch : 1 train_step : 1605 loss 0.14942987263202667\n",
      "Epoch : 1 train_step : 1606 loss 0.1829303801059723\n",
      "Epoch : 1 train_step : 1607 loss 0.1641155481338501\n",
      "Epoch : 1 train_step : 1608 loss 0.11113214492797852\n",
      "Epoch : 1 train_step : 1609 loss 0.04865673929452896\n",
      "Epoch : 1 train_step : 1610 loss 0.10560723394155502\n",
      "Epoch : 1 train_step : 1611 loss 0.07802614569664001\n",
      "Epoch : 1 train_step : 1612 loss 0.05569244176149368\n",
      "Epoch : 1 train_step : 1613 loss 0.09963901340961456\n",
      "Epoch : 1 train_step : 1614 loss 0.1635759323835373\n",
      "Epoch : 1 train_step : 1615 loss 0.2543388307094574\n",
      "Epoch : 1 train_step : 1616 loss 0.07480894029140472\n",
      "Epoch : 1 train_step : 1617 loss 0.08459965884685516\n",
      "Epoch : 1 train_step : 1618 loss 0.027723055332899094\n",
      "Epoch : 1 train_step : 1619 loss 0.013867316767573357\n",
      "Epoch : 1 train_step : 1620 loss 0.7089612483978271\n",
      "Epoch : 1 train_step : 1621 loss 0.07086825370788574\n",
      "Epoch : 1 train_step : 1622 loss 0.009758612141013145\n",
      "Epoch : 1 train_step : 1623 loss 0.06173631176352501\n",
      "Epoch : 1 train_step : 1624 loss 0.33090925216674805\n",
      "Epoch : 1 train_step : 1625 loss 0.14763978123664856\n",
      "Epoch : 1 train_step : 1626 loss 0.023285316303372383\n",
      "Epoch : 1 train_step : 1627 loss 0.46894571185112\n",
      "Epoch : 1 train_step : 1628 loss 0.5549630522727966\n",
      "Epoch : 1 train_step : 1629 loss 0.5557100772857666\n",
      "Epoch : 1 train_step : 1630 loss 0.04890080541372299\n",
      "Epoch : 1 train_step : 1631 loss 0.32200708985328674\n",
      "Epoch : 1 train_step : 1632 loss 0.14073404669761658\n",
      "Epoch : 1 train_step : 1633 loss 0.11768770217895508\n",
      "Epoch : 1 train_step : 1634 loss 0.12227462232112885\n",
      "Epoch : 1 train_step : 1635 loss 0.08721992373466492\n",
      "Epoch : 1 train_step : 1636 loss 0.19348284602165222\n",
      "Epoch : 1 train_step : 1637 loss 0.16942954063415527\n",
      "Epoch : 1 train_step : 1638 loss 0.057429321110248566\n",
      "Epoch : 1 train_step : 1639 loss 0.23425841331481934\n",
      "Epoch : 1 train_step : 1640 loss 0.0348527766764164\n",
      "Epoch : 1 train_step : 1641 loss 0.11305399984121323\n",
      "Epoch : 1 train_step : 1642 loss 0.08405481278896332\n",
      "Epoch : 1 train_step : 1643 loss 0.22914808988571167\n",
      "Epoch : 1 train_step : 1644 loss 0.10036960244178772\n",
      "Epoch : 1 train_step : 1645 loss 0.11083485186100006\n",
      "Epoch : 1 train_step : 1646 loss 0.21031640470027924\n",
      "Epoch : 1 train_step : 1647 loss 0.031820427626371384\n",
      "Epoch : 1 train_step : 1648 loss 0.0790790319442749\n",
      "Epoch : 1 train_step : 1649 loss 0.050347767770290375\n",
      "Epoch : 1 train_step : 1650 loss 0.026747331023216248\n",
      "Epoch : 1 train_step : 1651 loss 0.3062060475349426\n",
      "Epoch : 1 train_step : 1652 loss 0.0292230062186718\n",
      "Epoch : 1 train_step : 1653 loss 0.010446831583976746\n",
      "Epoch : 1 train_step : 1654 loss 0.19622217118740082\n",
      "Epoch : 1 train_step : 1655 loss 0.705464780330658\n",
      "Epoch : 1 train_step : 1656 loss 0.04299898445606232\n",
      "Epoch : 1 train_step : 1657 loss 0.06876140087842941\n",
      "Epoch : 1 train_step : 1658 loss 0.029263857752084732\n",
      "Epoch : 1 train_step : 1659 loss 0.15585382282733917\n",
      "Epoch : 1 train_step : 1660 loss 0.10204432159662247\n",
      "Epoch : 1 train_step : 1661 loss 0.18884235620498657\n",
      "Epoch : 1 train_step : 1662 loss 0.20151136815547943\n",
      "Epoch : 1 train_step : 1663 loss 0.03768986836075783\n",
      "Epoch : 1 train_step : 1664 loss 0.025616630911827087\n",
      "Epoch : 1 train_step : 1665 loss 0.16873130202293396\n",
      "Epoch : 1 train_step : 1666 loss 0.045766156166791916\n",
      "Epoch : 1 train_step : 1667 loss 0.07403811067342758\n",
      "Epoch : 1 train_step : 1668 loss 0.046852827072143555\n",
      "Epoch : 1 train_step : 1669 loss 0.053975384682416916\n",
      "Epoch : 1 train_step : 1670 loss 0.10693204402923584\n",
      "Epoch : 1 train_step : 1671 loss 0.050400204956531525\n",
      "Epoch : 1 train_step : 1672 loss 0.09853947162628174\n",
      "Epoch : 1 train_step : 1673 loss 0.03957924246788025\n",
      "Epoch : 1 train_step : 1674 loss 0.3093113601207733\n",
      "Epoch : 1 train_step : 1675 loss 0.06562013179063797\n",
      "Epoch : 1 train_step : 1676 loss 0.05083421617746353\n",
      "Epoch : 1 train_step : 1677 loss 0.07211410999298096\n",
      "Epoch : 1 train_step : 1678 loss 0.10616520047187805\n",
      "Epoch : 1 train_step : 1679 loss 0.023265209048986435\n",
      "Epoch : 1 train_step : 1680 loss 0.020065179094672203\n",
      "Epoch : 1 train_step : 1681 loss 0.04042653366923332\n",
      "Epoch : 1 train_step : 1682 loss 0.017477193847298622\n",
      "Epoch : 1 train_step : 1683 loss 0.3601517975330353\n",
      "Epoch : 1 train_step : 1684 loss 0.12514176964759827\n",
      "Epoch : 1 train_step : 1685 loss 0.007512965239584446\n",
      "Epoch : 1 train_step : 1686 loss 0.027014989405870438\n",
      "Epoch : 1 train_step : 1687 loss 0.002718102652579546\n",
      "Epoch : 1 train_step : 1688 loss 0.0713433027267456\n",
      "Epoch : 1 train_step : 1689 loss 0.13962464034557343\n",
      "Epoch : 1 train_step : 1690 loss 0.027406152337789536\n",
      "Epoch : 1 train_step : 1691 loss 0.04746541380882263\n",
      "Epoch : 1 train_step : 1692 loss 0.10535141825675964\n",
      "Epoch : 1 train_step : 1693 loss 0.33282941579818726\n",
      "Epoch : 1 train_step : 1694 loss 0.006223708391189575\n",
      "Epoch : 1 train_step : 1695 loss 0.016341594979166985\n",
      "Epoch : 1 train_step : 1696 loss 0.042423900216817856\n",
      "Epoch : 1 train_step : 1697 loss 0.029455196112394333\n",
      "Epoch : 1 train_step : 1698 loss 1.538737177848816\n",
      "Epoch : 1 train_step : 1699 loss 0.02286595106124878\n",
      "Epoch : 1 train_step : 1700 loss 0.032058000564575195\n",
      "Epoch : 1 train_step : 1701 loss 1.3280445337295532\n",
      "Epoch : 1 train_step : 1702 loss 0.014036145061254501\n",
      "Epoch : 1 train_step : 1703 loss 0.035117391496896744\n",
      "Epoch : 1 train_step : 1704 loss 0.054240632802248\n",
      "Epoch : 1 train_step : 1705 loss 0.04695357382297516\n",
      "Epoch : 1 train_step : 1706 loss 1.1537823677062988\n",
      "Epoch : 1 train_step : 1707 loss 0.0338471420109272\n",
      "Epoch : 1 train_step : 1708 loss 0.02256988361477852\n",
      "Epoch : 1 train_step : 1709 loss 0.054114773869514465\n",
      "Epoch : 1 train_step : 1710 loss 0.030597778037190437\n",
      "Epoch : 1 train_step : 1711 loss 0.4270133674144745\n",
      "Epoch : 1 train_step : 1712 loss 0.3053508698940277\n",
      "Epoch : 1 train_step : 1713 loss 0.02349805273115635\n",
      "Epoch : 1 train_step : 1714 loss 0.02475304901599884\n",
      "Epoch : 1 train_step : 1715 loss 0.054385025054216385\n",
      "Epoch : 1 train_step : 1716 loss 0.2284519374370575\n",
      "Epoch : 1 train_step : 1717 loss 0.27562516927719116\n",
      "Epoch : 1 train_step : 1718 loss 0.3839503526687622\n",
      "Epoch : 1 train_step : 1719 loss 0.23345769941806793\n",
      "Epoch : 1 train_step : 1720 loss 0.09967347979545593\n",
      "Epoch : 1 train_step : 1721 loss 0.016174420714378357\n",
      "Epoch : 1 train_step : 1722 loss 0.044165078550577164\n",
      "Epoch : 1 train_step : 1723 loss 0.16361738741397858\n",
      "Epoch : 1 train_step : 1724 loss 0.1571560502052307\n",
      "Epoch : 1 train_step : 1725 loss 0.2783593237400055\n",
      "Epoch : 1 train_step : 1726 loss 0.14618881046772003\n",
      "Epoch : 1 train_step : 1727 loss 0.0604788139462471\n",
      "Epoch : 1 train_step : 1728 loss 0.06581541895866394\n",
      "Epoch : 1 train_step : 1729 loss 0.08011578023433685\n",
      "Epoch : 1 train_step : 1730 loss 0.0809607058763504\n",
      "Epoch : 1 train_step : 1731 loss 0.09168017655611038\n",
      "Epoch : 1 train_step : 1732 loss 0.08733246475458145\n",
      "Epoch : 1 train_step : 1733 loss 0.10347975790500641\n",
      "Epoch : 1 train_step : 1734 loss 0.12185551226139069\n",
      "Epoch : 1 train_step : 1735 loss 0.1859646886587143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 train_step : 1736 loss 0.04577355831861496\n",
      "Epoch : 1 train_step : 1737 loss 0.09199757874011993\n",
      "Epoch : 1 train_step : 1738 loss 0.10932476073503494\n",
      "Epoch : 1 train_step : 1739 loss 0.22797971963882446\n",
      "Epoch : 1 train_step : 1740 loss 0.034271448850631714\n",
      "Epoch : 1 train_step : 1741 loss 0.05728008225560188\n",
      "Epoch : 1 train_step : 1742 loss 0.06796219944953918\n",
      "Epoch : 1 train_step : 1743 loss 0.0055526252835989\n",
      "Epoch : 1 train_step : 1744 loss 0.14202560484409332\n",
      "Epoch : 1 train_step : 1745 loss 0.06776107102632523\n",
      "Epoch : 1 train_step : 1746 loss 0.07005184888839722\n",
      "Epoch : 1 train_step : 1747 loss 0.46536576747894287\n",
      "Epoch : 1 train_step : 1748 loss 0.01769455149769783\n",
      "Epoch : 1 train_step : 1749 loss 0.026656650006771088\n",
      "Epoch : 1 train_step : 1750 loss 0.012109888717532158\n",
      "Epoch : 1 train_step : 1751 loss 0.3601658344268799\n",
      "Epoch : 1 train_step : 1752 loss 0.0330364927649498\n",
      "Epoch : 1 train_step : 1753 loss 0.005539584904909134\n",
      "Epoch : 1 train_step : 1754 loss 0.13198377192020416\n",
      "Epoch : 1 train_step : 1755 loss 1.0726516246795654\n",
      "Epoch : 1 train_step : 1756 loss 0.0061259036883711815\n",
      "Epoch : 1 train_step : 1757 loss 0.023401333019137383\n",
      "Epoch : 1 train_step : 1758 loss 0.03229951858520508\n",
      "Epoch : 1 train_step : 1759 loss 0.006740799639374018\n",
      "Epoch : 1 train_step : 1760 loss 0.04672791063785553\n",
      "Epoch : 1 train_step : 1761 loss 0.19598868489265442\n",
      "Epoch : 1 train_step : 1762 loss 0.05368601903319359\n",
      "Epoch : 1 train_step : 1763 loss 0.15697231888771057\n",
      "Epoch : 1 train_step : 1764 loss 0.08180621266365051\n",
      "Epoch : 1 train_step : 1765 loss 0.07387331873178482\n",
      "Epoch : 1 train_step : 1766 loss 0.031670644879341125\n",
      "Epoch : 1 train_step : 1767 loss 0.08787421882152557\n",
      "Epoch : 1 train_step : 1768 loss 0.18448606133460999\n",
      "Epoch : 1 train_step : 1769 loss 0.06058388948440552\n",
      "Epoch : 1 train_step : 1770 loss 0.07244834303855896\n",
      "Epoch : 1 train_step : 1771 loss 0.024097368121147156\n",
      "Epoch : 1 train_step : 1772 loss 0.47879689931869507\n",
      "Epoch : 1 train_step : 1773 loss 0.040442317724227905\n",
      "Epoch : 1 train_step : 1774 loss 0.04098730534315109\n",
      "Epoch : 1 train_step : 1775 loss 0.022013604640960693\n",
      "Epoch : 1 train_step : 1776 loss 0.04376912862062454\n",
      "Epoch : 1 train_step : 1777 loss 0.1547224074602127\n",
      "Epoch : 1 train_step : 1778 loss 0.04584989696741104\n",
      "Epoch : 1 train_step : 1779 loss 0.0051568374037742615\n",
      "Epoch : 1 train_step : 1780 loss 1.2902066707611084\n",
      "Epoch : 1 train_step : 1781 loss 0.11593207716941833\n",
      "Epoch : 1 train_step : 1782 loss 0.018891312181949615\n",
      "Epoch : 1 train_step : 1783 loss 0.16436608135700226\n",
      "Epoch : 1 train_step : 1784 loss 0.028967153280973434\n",
      "Epoch : 1 train_step : 1785 loss 0.09375163912773132\n",
      "Epoch : 1 train_step : 1786 loss 0.03831464797258377\n",
      "Epoch : 1 train_step : 1787 loss 0.022105958312749863\n",
      "Epoch : 1 train_step : 1788 loss 0.21502560377120972\n",
      "Epoch : 1 train_step : 1789 loss 0.040172867476940155\n",
      "Epoch : 1 train_step : 1790 loss 0.09359219670295715\n",
      "Epoch : 1 train_step : 1791 loss 0.012299608439207077\n",
      "Epoch : 1 train_step : 1792 loss 0.08151485025882721\n",
      "Epoch : 1 train_step : 1793 loss 0.021913673728704453\n",
      "Epoch : 1 train_step : 1794 loss 0.030680878087878227\n",
      "Epoch : 1 train_step : 1795 loss 0.013996008783578873\n",
      "Epoch : 1 train_step : 1796 loss 0.1510622352361679\n",
      "Epoch : 1 train_step : 1797 loss 0.3681677579879761\n",
      "Epoch : 1 train_step : 1798 loss 0.015354659408330917\n",
      "Epoch : 1 train_step : 1799 loss 0.07744394987821579\n",
      "Epoch : 1 train_step : 1800 loss 0.041300490498542786\n",
      "Epoch : 1 train_step : 1801 loss 0.018606677651405334\n",
      "Epoch : 1 train_step : 1802 loss 0.07924320548772812\n",
      "Epoch : 1 train_step : 1803 loss 0.05109989270567894\n",
      "Epoch : 1 train_step : 1804 loss 0.030595343559980392\n",
      "Epoch : 1 train_step : 1805 loss 0.012018926441669464\n",
      "Epoch : 1 train_step : 1806 loss 0.021809525787830353\n",
      "Epoch : 1 train_step : 1807 loss 0.022709960117936134\n",
      "Epoch : 1 train_step : 1808 loss 0.09023484587669373\n",
      "Epoch : 1 train_step : 1809 loss 0.057694122195243835\n",
      "Epoch : 1 train_step : 1810 loss 0.04702838510274887\n",
      "Epoch : 1 train_step : 1811 loss 0.06786102056503296\n",
      "Epoch : 1 train_step : 1812 loss 0.021326249465346336\n",
      "Epoch : 1 train_step : 1813 loss 0.04327322915196419\n",
      "Epoch : 1 train_step : 1814 loss 0.07497687637805939\n",
      "Epoch : 1 train_step : 1815 loss 0.0057433550246059895\n",
      "Epoch : 1 train_step : 1816 loss 0.05427860468626022\n",
      "Epoch : 1 train_step : 1817 loss 0.13410033285617828\n",
      "Epoch : 1 train_step : 1818 loss 0.07150888442993164\n",
      "Epoch : 1 train_step : 1819 loss 0.015214422717690468\n",
      "Epoch : 1 train_step : 1820 loss 0.006292055360972881\n",
      "Epoch : 1 train_step : 1821 loss 0.004699776880443096\n",
      "Epoch : 1 train_step : 1822 loss 1.593271017074585\n",
      "Epoch : 1 train_step : 1823 loss 0.05772172659635544\n",
      "Epoch : 1 train_step : 1824 loss 0.08058860898017883\n",
      "Epoch : 1 train_step : 1825 loss 0.051773086190223694\n",
      "Epoch : 1 train_step : 1826 loss 0.07803020626306534\n",
      "Epoch : 1 train_step : 1827 loss 0.04178889840841293\n",
      "Epoch : 1 train_step : 1828 loss 0.045809149742126465\n",
      "Epoch : 1 train_step : 1829 loss 0.08374065160751343\n",
      "Epoch : 1 train_step : 1830 loss 0.06964520364999771\n",
      "Epoch : 1 train_step : 1831 loss 0.7391286492347717\n",
      "Epoch : 1 train_step : 1832 loss 0.038767628371715546\n",
      "Epoch : 1 train_step : 1833 loss 0.06321930885314941\n",
      "Epoch : 1 train_step : 1834 loss 0.11904206871986389\n",
      "Epoch : 1 train_step : 1835 loss 0.032095227390527725\n",
      "Epoch : 1 train_step : 1836 loss 0.05259428173303604\n",
      "Epoch : 1 train_step : 1837 loss 0.015091169625520706\n",
      "Epoch : 1 train_step : 1838 loss 0.20211845636367798\n",
      "Epoch : 1 train_step : 1839 loss 0.04211386293172836\n",
      "Epoch : 1 train_step : 1840 loss 0.02424529753625393\n",
      "Epoch : 1 train_step : 1841 loss 0.04809761792421341\n",
      "Epoch : 1 train_step : 1842 loss 0.1342639923095703\n",
      "Epoch : 1 train_step : 1843 loss 0.02202400378882885\n",
      "Epoch : 1 train_step : 1844 loss 0.3051336407661438\n",
      "Epoch : 1 train_step : 1845 loss 0.1162123829126358\n",
      "Epoch : 1 train_step : 1846 loss 0.10563898086547852\n",
      "Epoch : 1 train_step : 1847 loss 0.06756529957056046\n",
      "Epoch : 1 train_step : 1848 loss 0.227895587682724\n",
      "Epoch : 1 train_step : 1849 loss 0.1103963553905487\n",
      "Epoch : 1 train_step : 1850 loss 0.048996925354003906\n",
      "Epoch : 1 train_step : 1851 loss 0.020247850567102432\n",
      "Epoch : 1 train_step : 1852 loss 0.0542878583073616\n",
      "Epoch : 1 train_step : 1853 loss 1.3650768995285034\n",
      "Epoch : 1 train_step : 1854 loss 0.04407181590795517\n",
      "Epoch : 1 train_step : 1855 loss 0.37565430998802185\n",
      "Epoch : 1 train_step : 1856 loss 0.2328852415084839\n",
      "Epoch : 1 train_step : 1857 loss 0.036654289811849594\n",
      "Epoch : 1 train_step : 1858 loss 0.05341180041432381\n",
      "Epoch : 1 train_step : 1859 loss 0.09367978572845459\n",
      "Epoch : 1 train_step : 1860 loss 0.06453465670347214\n",
      "Epoch : 1 train_step : 1861 loss 0.37591373920440674\n",
      "Epoch : 1 train_step : 1862 loss 0.07096745818853378\n",
      "Epoch : 1 train_step : 1863 loss 0.2874535918235779\n",
      "Epoch : 1 train_step : 1864 loss 0.30208539962768555\n",
      "Epoch : 1 train_step : 1865 loss 0.07989591360092163\n",
      "Epoch : 1 train_step : 1866 loss 0.06257526576519012\n",
      "Epoch : 1 train_step : 1867 loss 0.1269276887178421\n",
      "Epoch : 1 train_step : 1868 loss 0.07799229025840759\n",
      "Epoch : 1 train_step : 1869 loss 0.12957894802093506\n",
      "Epoch : 1 train_step : 1870 loss 0.23468893766403198\n",
      "Epoch : 1 train_step : 1871 loss 0.07776666432619095\n",
      "Epoch : 1 train_step : 1872 loss 0.06226677820086479\n",
      "Epoch : 1 train_step : 1873 loss 0.04079621285200119\n",
      "Epoch : 1 train_step : 1874 loss 0.12037140130996704\n",
      "Epoch : 1 train_step : 1875 loss 0.41735753417015076\n",
      "Epoch : 1 train_step : 1876 loss 0.06932476907968521\n",
      "Epoch : 1 train_step : 1877 loss 0.07779007405042648\n",
      "Epoch : 1 train_step : 1878 loss 0.06199448183178902\n",
      "Epoch : 1 train_step : 1879 loss 0.03362923860549927\n",
      "Epoch : 1 train_step : 1880 loss 0.048991475254297256\n",
      "Epoch : 1 train_step : 1881 loss 0.08418455719947815\n",
      "Epoch : 1 train_step : 1882 loss 0.02782275341451168\n",
      "Epoch : 1 train_step : 1883 loss 0.027677755802869797\n",
      "Epoch : 1 train_step : 1884 loss 0.05167496204376221\n",
      "Epoch : 1 train_step : 1885 loss 0.05667576938867569\n",
      "Epoch : 1 train_step : 1886 loss 0.1828671246767044\n",
      "Epoch : 1 train_step : 1887 loss 0.03791690990328789\n",
      "Epoch : 1 train_step : 1888 loss 0.02770816534757614\n",
      "Epoch : 1 train_step : 1889 loss 0.07869870960712433\n",
      "Epoch : 1 train_step : 1890 loss 0.4975500702857971\n",
      "Epoch : 1 train_step : 1891 loss 0.014065496623516083\n",
      "Epoch : 1 train_step : 1892 loss 0.05526908114552498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 train_step : 1893 loss 0.05391763895750046\n",
      "Epoch : 1 train_step : 1894 loss 0.03149048611521721\n",
      "Epoch : 1 train_step : 1895 loss 0.04974920675158501\n",
      "Epoch : 1 train_step : 1896 loss 0.04059583321213722\n",
      "Epoch : 1 train_step : 1897 loss 0.04140577092766762\n",
      "Epoch : 1 train_step : 1898 loss 0.3720054626464844\n",
      "Epoch : 1 train_step : 1899 loss 1.1449779272079468\n",
      "Epoch : 1 train_step : 1900 loss 0.020182933658361435\n",
      "Epoch : 1 train_step : 1901 loss 0.03671405091881752\n",
      "Epoch : 1 train_step : 1902 loss 0.03883782774209976\n",
      "Epoch : 1 train_step : 1903 loss 0.1542557030916214\n",
      "Epoch : 1 train_step : 1904 loss 0.0546833798289299\n",
      "Epoch : 1 train_step : 1905 loss 0.06592375040054321\n",
      "Epoch : 1 train_step : 1906 loss 0.03037431091070175\n",
      "Epoch : 1 train_step : 1907 loss 0.09019851684570312\n",
      "Epoch : 1 train_step : 1908 loss 0.03945880010724068\n",
      "Epoch : 1 train_step : 1909 loss 0.12060848623514175\n",
      "Epoch : 1 train_step : 1910 loss 0.03352544829249382\n",
      "Epoch : 1 train_step : 1911 loss 0.030028726905584335\n",
      "Epoch : 1 train_step : 1912 loss 0.05666396766901016\n",
      "Epoch : 1 train_step : 1913 loss 0.022370584309101105\n"
     ]
    }
   ],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_acc = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_acc = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "\n",
    "template = \"Epoch {} : detection train loss {:5f}, accuracy {:.3f}, val loss {:5f}, val accuracy {:.3f}\"\n",
    "\n",
    "optimizer= tf.keras.optimizers.Adam(learning_rate=1E-4)\n",
    "EPOCH = 20\n",
    "\n",
    "log_dir = \"logs/detection\"\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "for epoch in range(1, EPOCH+1): \n",
    "    train_loss.reset_states()\n",
    "    train_acc.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_acc.reset_states()\n",
    "\n",
    "    for i, (patches, labels) in enumerate(train_ds):\n",
    "        loss = train_step(patches, labels, model, optimizer, \\\n",
    "                             train_loss, train_acc)\n",
    "        print(\"Epoch : {} train_step : {} loss {}\".format(epoch, i, loss))\n",
    "    \n",
    "    #print(\"Epoch : {}\".format(train_acc.result().numpy()))\n",
    "    for i, (patches, labels) in enumerate(test_ds):\n",
    "        loss = test_step(patches, labels, model, test_loss, test_acc)\n",
    "        print(\"Epoch : {} test_step : {} loss {}\".format(epoch, i, loss))\n",
    "    print(template.format(epoch,\n",
    "                      train_loss.result().numpy(),\n",
    "                      train_acc.result().numpy(),\n",
    "                     test_loss.result().numpy(),\n",
    "                     test_acc.result().numpy()))\n",
    "\n",
    "    with summary_writer.as_default():\n",
    "        tf.summary.scalar('train_loss', train_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('train_acc', train_acc.result().numpy(), step=epoch)\n",
    "        tf.summary.scalar('test_loss', test_loss.result().numpy(), step=epoch)\n",
    "        tf.summary.scalar('test_acc', test_acc.result().numpy(), step=epoch)\n",
    "    model.save(\"checkpoints/detection/model-{}.h5\".format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0555acf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46ad067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
