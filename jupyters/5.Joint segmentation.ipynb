{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f80f5c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import json, os, sys\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from data.loader import load\n",
    "from utils.session_config import setup_gpus\n",
    "setup_gpus(True, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d646e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pycocotools.coco import COCO\n",
    "train_ids = np.load(\"annotations/train_ids.npy\")\n",
    "test_ids = np.load(\"annotations/val_ids.npy\")\n",
    "coco = COCO(\"annotations/integrated_annotation.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "811b48d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function load.<locals>.<lambda> at 0x7f3217d5f598> and will run it as-is.\n",
      "Cause: could not parse the source code of <function load.<locals>.<lambda> at 0x7f3217d5f598>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function load.<locals>.<lambda> at 0x7f3217d5f598> and will run it as-is.\n",
      "Cause: could not parse the source code of <function load.<locals>.<lambda> at 0x7f3217d5f598>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function load.<locals>.<lambda> at 0x7f30e05b1488> and will run it as-is.\n",
      "Cause: could not parse the source code of <function load.<locals>.<lambda> at 0x7f30e05b1488>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function load.<locals>.<lambda> at 0x7f30e05b1488> and will run it as-is.\n",
      "Cause: could not parse the source code of <function load.<locals>.<lambda> at 0x7f30e05b1488>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "def shape_process(patches, labels, masks, origins):\n",
    "    patches = tf.reshape(patches, [-1, 500, 512, 3])\n",
    "    patches = tf.image.resize(patches, [224,224])\n",
    "    labels = tf.reshape(labels, [-1])\n",
    "    masks = tf.reshape(masks, [-1, 500, 512, 3])\n",
    "    origins = tf.reshape(origins, [-1, 500, 512, 3])\n",
    "    masks = tf.image.resize(masks, [512,512], method='nearest')\n",
    "    origins = tf.image.resize(origins, [512,512], method='nearest')\n",
    "    return patches, labels, masks, origins\n",
    "\n",
    "train_ds = load(train_ids, coco, \"detection\")\n",
    "train_ds = train_ds.batch(8).map(shape_process).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "#train_ds = train_ds.cache().batch(16).map(shape_process).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_ds = load(test_ids, coco, \"detection\")\n",
    "test_ds = test_ds.map(shape_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d73517a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": "InvalidArgumentError: Input to reshape is a tensor with 3447552000 values, but the requested shape has 14592000 [Op:Reshape]\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 247, in __call__\n    return func(device, token, args)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 135, in __call__\n    ret = self._func(*args)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/files/cnsi-ex/data/loader.py\", line 98, in data_process\n    patches, labels = detection_pipeline(image_array, object_boxes, resize_H, resize_W)\n\n  File \"/home/files/cnsi-ex/data/loader.py\", line 48, in detection_pipeline\n    patches = tf.reshape(patches, (19, int(resize_H/10),resize_W,3))\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\", line 206, in wrapper\n    return target(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\", line 195, in reshape\n    result = gen_array_ops.reshape(tensor, shape, name)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 8393, in reshape\n    tensor, shape, name=name, ctx=_ctx)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 8418, in reshape_eager_fallback\n    ctx=ctx, name=name)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\n    inputs, attrs, num_outputs)\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Input to reshape is a tensor with 3447552000 values, but the requested shape has 14592000 [Op:Reshape]\n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-41275d4628e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mpatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    759\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    745\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2726\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2727\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2728\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2729\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2730\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6895\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6896\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6897\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6898\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: InvalidArgumentError: Input to reshape is a tensor with 3447552000 values, but the requested shape has 14592000 [Op:Reshape]\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 247, in __call__\n    return func(device, token, args)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 135, in __call__\n    ret = self._func(*args)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/files/cnsi-ex/data/loader.py\", line 98, in data_process\n    patches, labels = detection_pipeline(image_array, object_boxes, resize_H, resize_W)\n\n  File \"/home/files/cnsi-ex/data/loader.py\", line 48, in detection_pipeline\n    patches = tf.reshape(patches, (19, int(resize_H/10),resize_W,3))\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\", line 206, in wrapper\n    return target(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\", line 195, in reshape\n    result = gen_array_ops.reshape(tensor, shape, name)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 8393, in reshape\n    tensor, shape, name=name, ctx=_ctx)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 8418, in reshape_eager_fallback\n    ctx=ctx, name=name)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\n    inputs, attrs, num_outputs)\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Input to reshape is a tensor with 3447552000 values, but the requested shape has 14592000 [Op:Reshape]\n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "for patches, labels, mask, origin in train_ds.take(1):\n",
    "    print(patches.shape)\n",
    "    print(labels)\n",
    "    print(mask.shape)\n",
    "    print(origin.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb4940e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec77664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc4c95f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f6032b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06afdf66",
   "metadata": {},
   "source": [
    "# 모델 빌드 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21063e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model = tf.keras.models.load_model(\"models/detection.h5\")\n",
    "segmentation_model = tf.keras.models.load_model(\"models/segmentation.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74006478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cec65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CCE = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "@tf.function\n",
    "def detection_train_step(images, labels, model, optimizer, det_train_loss, det_train_acc):\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds = model(images, training=True)\n",
    "        loss = CCE(labels,preds)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    det_train_loss(loss)\n",
    "    det_train_acc(labels, preds)\n",
    "@tf.function\n",
    "def detection_test_step(images, labels, model, det_test_loss, det_test_acc):\n",
    "    preds = model(images, training=False)\n",
    "    loss = CCE(labels,preds)\n",
    "    det_test_loss(loss)\n",
    "    det_test_acc(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff71873",
   "metadata": {},
   "outputs": [],
   "source": [
    "BCE = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "@tf.function\n",
    "def segmentation_train_step(images, labels, model, optimizer, seg_train_loss, seg_train_acc):\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds = model(images, training=True)\n",
    "        loss = BCE(labels,preds)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    seg_train_loss(loss)\n",
    "    seg_train_acc(labels, preds)\n",
    "@tf.function\n",
    "def segmentation_test_step(images, labels, model, seg_test_loss, seg_test_acc):\n",
    "    preds = model(images, training=False)\n",
    "    loss = BCE(labels,preds)\n",
    "    seg_test_loss(loss)\n",
    "    seg_test_acc(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948bbaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "det_train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "det_train_acc = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "det_test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "det_test_acc = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "seg_train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "seg_train_acc = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "seg_test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "seg_test_acc = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "template_det = \"Epoch {} : detection train loss {:5f}, accuracy {:.3f}, val loss {:5f}, val accuracy {:.3f}\"\n",
    "template_seg = \"Epoch {} : segmentation train loss {:5f}, accuracy {:.3f}, val loss {:5f}, val accuracy {:.3f}\"\n",
    "\n",
    "optimizer1 = tf.keras.optimizers.Adam(learning_rate=1E-3)\n",
    "optimizer2 = tf.keras.optimizers.Adam(learning_rate=1E-3)\n",
    "EPOCH = 20\n",
    "\n",
    "log_dir = \"logs/exp1\"\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "for epoch in range(1, EPOCH+1): \n",
    "    det_train_loss.reset_states()\n",
    "    det_train_acc.reset_states()\n",
    "    det_test_loss.reset_states()\n",
    "    det_test_acc.reset_states()\n",
    "    seg_train_loss.reset_states()\n",
    "    seg_train_acc.reset_states()\n",
    "    seg_test_loss.reset_states()\n",
    "    seg_test_acc.reset_states()\n",
    "\n",
    "    for i, (patches, labels, mask, origin) in enumerate(train_ds):\n",
    "        detection_train_step(patches, labels, detection_model, optimizer1, /\n",
    "                             det_train_loss, det_train_acc)\n",
    "        segmentation_train_step(mask, origin, model, optimizer2,/\n",
    "                                seg_train_loss, seg_train_acc)\n",
    "\n",
    "    for i, (patches, labels, mask, origin) in enumerate(test_ds):\n",
    "        detection_train_step(patches, labels, detection_model, optimizer2, /\n",
    "                             det_test_loss, det_test_acc)\n",
    "        segmentation_train_step(mask, origin, model, optimizer2,/\n",
    "                                seg_test_loss, seg_test_acc)\n",
    "        print(template.format(epoch,\n",
    "                          train_loss.result().numpy(),\n",
    "                          train_acc.result().numpy(),\n",
    "                         test_loss.result().numpy(),\n",
    "                         test_acc.result().numpy()))\n",
    "        \n",
    "    for imgs, labels in val_ds:\n",
    "        test_step(imgs, labels, model)\n",
    "    \n",
    "\n",
    "    with summary_writer.as_default():\n",
    "        tf.summary.scalar('train_loss', train_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('train_acc', train_acc.result().numpy(), step=epoch)\n",
    "        tf.summary.scalar('test_loss', test_loss.result().numpy(), step=epoch)\n",
    "        tf.summary.scalar('test_acc', test_acc.result().numpy(), step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0555acf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"checkpoints/detection_test_v1/model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e102c62",
   "metadata": {},
   "source": [
    "# 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b58e738",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_modelval_ds = val_ds.map(lambda x: tf.py_function(data_process, [x], [tf.float32, tf.int32])).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.map(lambda x: tf.py_function(data_process, [x], [tf.float32, tf.int32])).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.map(lambda x: tf.py_function(data_process, [x], [tf.float32, tf.int32])).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.map(lambda x: tf.py_function(data_process, [x], [tf.float32, tf.int32])).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.map(lambda x: tf.py_function(data_process, [x], [tf.float32, tf.int32])).prefetch(buffer_size=AUTOTUNE)\n",
    "(\"checkpoints/detection_test_v1/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bd8f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.data.Dataset.from_tensor_slices(val_ids).cache().batch(1)\n",
    "val_ds = val_ds.map(lambda x: tf.py_function(data_process, [x], [tf.float32, tf.int32])).prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dc358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, label in val_ds.take(1):\n",
    "    print(img.shape)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd04f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "for r in range(5):\n",
    "    for c in range(4):\n",
    "        ax = fig.add_subplot(5,4,r*4 + c + 1)\n",
    "        if r*4+c+1>19:\n",
    "            break\n",
    "        ax.imshow((img[r*4+c]+1)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25ec957",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46ad067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
